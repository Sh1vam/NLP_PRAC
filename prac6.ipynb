{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5069d625-3484-43fc-96d2-d088083ce40f",
   "metadata": {},
   "source": [
    "# Practical 6\n",
    "## POS tagging part 2: Analyze the result of POS Tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f3a912-2c45-4875-8f06-7509f8aa70fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_lib import *\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a78ce7-69bd-4d5a-b867-5c33df7ef741",
   "metadata": {},
   "source": [
    "### Load Dataset and Normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "236b33cd-e1ca-404c-bc33-05b64bc78523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[The, Arizona, Corporations, Commission, autho...</td>\n",
       "      <td>[DT, NNP, NNP, NNP, VBD, DT, CD, NN, NN, NN, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[The, ruling, follows, a, host, of, problems, ...</td>\n",
       "      <td>[DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[The, Arizona, regulatory, ruling, calls, for,...</td>\n",
       "      <td>[DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[The, company, had, sought, increases, totalin...</td>\n",
       "      <td>[DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[The, decision, was, announced, after, trading...</td>\n",
       "      <td>[DT, NN, VBD, VBN, IN, NN, VBD, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           sentence  \\\n",
       "0      0  [The, Arizona, Corporations, Commission, autho...   \n",
       "1      1  [The, ruling, follows, a, host, of, problems, ...   \n",
       "2      2  [The, Arizona, regulatory, ruling, calls, for,...   \n",
       "3      3  [The, company, had, sought, increases, totalin...   \n",
       "4      4  [The, decision, was, announced, after, trading...   \n",
       "\n",
       "                                              labels  \n",
       "0  [DT, NNP, NNP, NNP, VBD, DT, CD, NN, NN, NN, I...  \n",
       "1  [DT, NN, VBZ, DT, NN, IN, NNS, IN, NNP, NNP, ,...  \n",
       "2  [DT, NNP, JJ, NN, VBZ, IN, $, CD, CD, IN, JJ, ...  \n",
       "3  [DT, NN, VBD, VBN, NNS, VBG, $, CD, CD, ,, CC,...  \n",
       "4                 [DT, NN, VBD, VBN, IN, NN, VBD, .]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset using pandas\n",
    "df = pd.read_json('pos.json')\n",
    "\n",
    "# Normalize the dataset to access sentences and labels\n",
    "sentences = df['sentence'].tolist()\n",
    "tags = df['labels'].tolist()\n",
    "\n",
    "# Convert tags to a DataFrame for easier manipulation\n",
    "tags_df = pd.DataFrame(tags)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c73ddd-f69d-4143-a1cb-e8e219987148",
   "metadata": {},
   "source": [
    "### Calculate Initial Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79e22ec-d0fb-41c5-abaa-8879810bb532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Probabilities: {'NNP': 0.22561968518183462, 'DT': 0.213859236475484, 'IN': 0.11416681744165008, '``': 0.08015198118328207, 'PRP': 0.05844038357155781, 'RB': 0.054640853989506064, 'CC': 0.053374344128822145, 'NNS': 0.0499366745069658, 'JJ': 0.04034738556178759, 'NN': 0.035824136059345035, 'VBG': 0.012303238646643748, 'PRP$': 0.009227428984982812, 'CD': 0.007960919124298896, 'WRB': 0.00741812918400579, 'VBN': 0.006151619323321874, 'EX': 0.0041613895422471505, '-LRB-': 0.0036185996019540436, 'WP': 0.0032567396417586395, 'TO': 0.002894879681563235, 'VB': 0.002171159761172426, 'NNPS': 0.001990229781074724, 'JJS': 0.001990229781074724, 'RBR': 0.0012665098606839153, 'VBZ': 0.0012665098606839153, 'MD': 0.0012665098606839153, 'JJR': 0.0012665098606839153, ':': 0.001085579880586213, 'VBD': 0.001085579880586213, 'RBS': 0.0007237199203908088, 'PDT': 0.0007237199203908088, 'SYM': 0.0007237199203908088, \"''\": 0.0005427899402931065, 'WDT': 0.0003618599601954044, 'VBP': 0.0001809299800977022}\n"
     ]
    }
   ],
   "source": [
    "initial_prob = tags_df[0].value_counts(normalize=True).to_dict()\n",
    "print(\"Initial Probabilities:\", initial_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1834f32f-4654-4744-9d06-aa117f8017e3",
   "metadata": {},
   "source": [
    "### Calculate Transition Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf8d3c-c85e-4280-87bb-39f7416f5725",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counter = Counter([tag for tag_seq in tags for tag in tag_seq])\n",
    "transition_counter = defaultdict(Counter)\n",
    "\n",
    "for tag_seq in tags:\n",
    "    for i in range(1, len(tag_seq)):\n",
    "        transition_counter[tag_seq[i - 1]][tag_seq[i]] += 1\n",
    "\n",
    "transition_prob = {\n",
    "    tag: {next_tag: transition_counter[tag][next_tag] / tag_counter[tag] for next_tag in transition_counter[tag]}\n",
    "    for tag in transition_counter\n",
    "}\n",
    "print(transition_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f69cd2-6e1f-4b69-9bda-67e357693ec8",
   "metadata": {},
   "source": [
    "### Calculate Emission Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad05f2a6-acf1-4a78-b095-cdc9291199b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emission_counter = defaultdict(Counter)\n",
    "word_counter = Counter([word for sentence in sentences for word in sentence])\n",
    "\n",
    "for sentence, tag_seq in zip(sentences, tags):\n",
    "    for word, tag in zip(sentence, tag_seq):\n",
    "        emission_counter[tag][word] += 1\n",
    "\n",
    "emission_prob = {\n",
    "    tag: {word: emission_counter[tag][word] / tag_counter[tag] for word in emission_counter[tag]}\n",
    "    for tag in emission_counter\n",
    "}\n",
    "print(emission_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba9eb38-d3b9-448b-8f35-bf5a25f988f8",
   "metadata": {},
   "source": [
    "### Implement the Viterbi Algorithm for POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddf71d66-fe9e-4eca-93c5-5c0e845cbe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(sentence, tags, initial_prob, transition_prob, emission_prob):\n",
    "    n = len(sentence)\n",
    "    m = len(tags)\n",
    "    \n",
    "    # Initialize viterbi and backpointer matrices\n",
    "    viterbi = np.zeros((m, n))\n",
    "    backpointer = np.zeros((m, n), dtype=int)\n",
    "    \n",
    "    # Convert tags to index\n",
    "    tag_index = {tag: i for i, tag in enumerate(tags)}\n",
    "    \n",
    "    # Initialization step\n",
    "    for tag in tags:\n",
    "        if sentence[0] in emission_prob[tag]:\n",
    "            viterbi[tag_index[tag], 0] = initial_prob.get(tag, 0) * emission_prob[tag].get(sentence[0], 1e-6)\n",
    "        else:\n",
    "            viterbi[tag_index[tag], 0] = initial_prob.get(tag, 0) * 1e-6  # Small probability for unseen words\n",
    "\n",
    "    # Recursion step\n",
    "    for t in range(1, n):\n",
    "        for curr_tag in tags:\n",
    "            max_prob, max_state = max(\n",
    "                (viterbi[tag_index[prev_tag], t - 1] * transition_prob[prev_tag].get(curr_tag, 1e-6) *\n",
    "                 emission_prob[curr_tag].get(sentence[t], 1e-6), tag_index[prev_tag])\n",
    "                for prev_tag in tags\n",
    "            )\n",
    "            viterbi[tag_index[curr_tag], t] = max_prob\n",
    "            backpointer[tag_index[curr_tag], t] = max_state\n",
    "\n",
    "    # Termination step\n",
    "    best_path_prob = max(viterbi[tag_index[tag], n - 1] for tag in tags)\n",
    "    best_last_tag = np.argmax([viterbi[tag_index[tag], n - 1] for tag in tags])\n",
    "\n",
    "    # Backtrace the best path\n",
    "    best_path = [best_last_tag]\n",
    "    for t in range(n - 1, 0, -1):\n",
    "        best_last_tag = backpointer[best_last_tag, t]\n",
    "        best_path.insert(0, best_last_tag)\n",
    "\n",
    "    # Convert indices back to tags\n",
    "    index_tag = {i: tag for tag, i in tag_index.items()}\n",
    "    best_path = [index_tag[i] for i in best_path]\n",
    "    \n",
    "    return best_path, best_path_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a9890-4836-4519-b04a-07b8e7b30cb0",
   "metadata": {},
   "source": [
    "### Testing the Model with a Sample Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b50c7bb4-a0bd-4ad6-8bcc-b15c8e7d15c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: ['The', 'Arizona', 'Corporations', 'Commission', 'authorized', 'an', '11.5', '%', 'rate', 'increase', 'at', 'Tucson', 'Electric', 'Power', 'Co.', ',', 'substantially', 'lower', 'than', 'recommended', 'last', 'month', 'by', 'a', 'commission', 'hearing', 'officer', 'and', 'barely', 'half', 'the', 'rise', 'sought', 'by', 'the', 'utility', '.']\n",
      "Predicted Tags: ['DT', 'NNP', 'NNP', 'NNP', 'VBD', 'DT', 'CD', 'NN', 'NN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'RB', 'JJR', 'IN', 'VBN', 'JJ', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'CC', 'RB', 'PDT', 'DT', 'NN', 'VBN', 'IN', 'DT', 'NN', '.']\n",
      "Probability of Best Path: 4.746027399410256e-112\n"
     ]
    }
   ],
   "source": [
    "test_sentence = sentences[0]  # Using the first sentence in the dataset as a test example\n",
    "\n",
    "# Get unique tags\n",
    "unique_tags = list(tag_counter.keys())\n",
    "\n",
    "# Run Viterbi algorithm on the test sentence\n",
    "best_path, best_prob = viterbi(test_sentence, unique_tags, initial_prob, transition_prob, emission_prob)\n",
    "\n",
    "print(\"Sentence:\", test_sentence)\n",
    "print(\"Predicted Tags:\", best_path)\n",
    "print(\"Probability of Best Path:\", best_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef3f840-afd0-4798-8c93-dfbbb7f7b967",
   "metadata": {},
   "source": [
    "### Original Sentence and its tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef317b78-44de-4657-8161-e14b4856f0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Arizona', 'Corporations', 'Commission', 'authorized', 'an', '11.5', '%', 'rate', 'increase', 'at', 'Tucson', 'Electric', 'Power', 'Co.', ',', 'substantially', 'lower', 'than', 'recommended', 'last', 'month', 'by', 'a', 'commission', 'hearing', 'officer', 'and', 'barely', 'half', 'the', 'rise', 'sought', 'by', 'the', 'utility', '.'] ['DT', 'NNP', 'NNP', 'NNP', 'VBD', 'DT', 'CD', 'NN', 'NN', 'NN', 'IN', 'NNP', 'NNP', 'NNP', 'NNP', ',', 'RB', 'JJR', 'IN', 'VBN', 'JJ', 'NN', 'IN', 'DT', 'NN', 'NN', 'NN', 'CC', 'RB', 'PDT', 'DT', 'NN', 'VBN', 'IN', 'DT', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0],tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca7791a-4496-461b-b5a3-4995e70bdfb5",
   "metadata": {},
   "source": [
    "### Evaluate the Model on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "401f89e9-33b6-4a27-9025-df296a9dc071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM POS Tagging Accuracy: 0.975623823690122\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for sentence, true_tags in zip(sentences, tags):\n",
    "    predicted_tags, _ = viterbi(sentence, unique_tags, initial_prob, transition_prob, emission_prob)\n",
    "    correct += sum(p == t for p, t in zip(predicted_tags, true_tags))\n",
    "    total += len(true_tags)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(\"HMM POS Tagging Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197d993-1e2b-43c2-8f53-101033521159",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "1. **Loading Data with Pandas**: The dataset is loaded and normalized with `pd.json_normalize()`, making it easy to extract sentences and labels.\n",
    "2. **Initial Probabilities**: We calculate the probability of each tag being the starting tag.\n",
    "3. **Transition Probabilities**: Counts transitions between tags and calculates probabilities based on those transitions.\n",
    "4. **Emission Probabilities**: Calculates the probability of a word given a tag.\n",
    "5. **Viterbi Algorithm**: Implements Viterbi for decoding the sequence, finding the most likely POS tag sequence.\n",
    "6. **Testing and Evaluation**: Tests the model on a sample sentence and calculates overall accuracy across the dataset.\n",
    "\n",
    "This code work as a standalone POS tagging model based on HMM principles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28235fcd-deeb-4b61-b536-8df37da58e72",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33214381-7392-4596-8e52-eb1b931c5fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hmm_pos_tagger_model.joblib']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the initial, transition, and emission probabilities\n",
    "model = {\n",
    "    'initial_prob': initial_prob,\n",
    "    'transition_prob': transition_prob,\n",
    "    'emission_prob': emission_prob,\n",
    "    'unique_tags': unique_tags  # Save the list of unique tags as well\n",
    "}\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model, 'hmm_pos_tagger_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0464f81f-94a7-4cee-a8ae-dbcf467963e9",
   "metadata": {},
   "source": [
    "### Using the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c43a32-4c11-4466-b140-e55907248d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: ['The', 'company', 'announced', 'a', 'new', 'policy']\n",
      "Predicted Tags: ['DT', 'NN', 'VBD', 'DT', 'JJ', 'NN']\n",
      "Probability of Best Path: 2.293859621014805e-15\n"
     ]
    }
   ],
   "source": [
    "# Load the model from the file\n",
    "loaded_model = joblib.load('hmm_pos_tagger_model.joblib')\n",
    "\n",
    "# Retrieve the probabilities\n",
    "initial_prob = loaded_model['initial_prob']\n",
    "transition_prob = loaded_model['transition_prob']\n",
    "emission_prob = loaded_model['emission_prob']\n",
    "unique_tags = loaded_model['unique_tags']\n",
    "\n",
    "# Now you can use the loaded model with the Viterbi function\n",
    "test_sentence = [\"The\", \"company\", \"announced\", \"a\", \"new\", \"policy\"]\n",
    "best_path, best_prob = viterbi(test_sentence, unique_tags, initial_prob, transition_prob, emission_prob)\n",
    "\n",
    "print(\"Sentence:\", test_sentence)\n",
    "print(\"Predicted Tags:\", best_path)\n",
    "print(\"Probability of Best Path:\", best_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edccd014-6430-407c-ad93-a9b2b9dadcb2",
   "metadata": {},
   "source": [
    "### POS Tagging using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a352494-f2e3-4acb-b58c-deba4767a8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DET'),\n",
       " ('company', 'NOUN'),\n",
       " ('announced', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('new', 'ADJ'),\n",
       " ('policy', 'NOUN')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(\"The company announced a new policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22ce32-7504-47a1-ba82-5a69a3f53795",
   "metadata": {},
   "source": [
    "### POS Tagging using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57c9236b-c144-4592-9bc7-a3be74692718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('company', 'NN'),\n",
       " ('announced', 'VBD'),\n",
       " ('new', 'JJ'),\n",
       " ('policy', 'NN')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pos_tag(\"The company announced a new policy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
