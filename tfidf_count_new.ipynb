{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d61017c5-2691-4985-a2d5-84c682f3d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nlp_lib import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c9e9aa8-38f8-4db6-a8a0-6d1c32116c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"imdbproc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d660630-3c01-47af-b201-32c7bcba68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['procss']=df['lemmatized'].apply(removes_specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d190a20-817e-42e0-98d4-f899aa9c3e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>porter_stemmed</th>\n",
       "      <th>lancaster_stemmed</th>\n",
       "      <th>snowball_stemming</th>\n",
       "      <th>regexp_stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>procss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>['one', 'reviewers', 'mentioned', 'watching', ...</td>\n",
       "      <td>['one', 'review', 'mention', 'watch', '1', 'oz...</td>\n",
       "      <td>['on', 'review', 'ment', 'watch', '1', 'oz', '...</td>\n",
       "      <td>['one', 'review', 'mention', 'watch', '1', 'oz...</td>\n",
       "      <td>['one', 'reviewer', 'mentioned', 'watch', '1',...</td>\n",
       "      <td>['one', 'reviewer', 'mentioned', 'watching', '...</td>\n",
       "      <td>one reviewer mentioned watching 1 oz episode y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a wonderful little production filming techniqu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>['wonderful', 'little', 'production', 'filming...</td>\n",
       "      <td>['wonder', 'littl', 'product', 'film', 'techni...</td>\n",
       "      <td>['wond', 'littl', 'produc', 'film', 'techn', '...</td>\n",
       "      <td>['wonder', 'littl', 'product', 'film', 'techni...</td>\n",
       "      <td>['wonderful', 'littl', 'production', 'film', '...</td>\n",
       "      <td>['wonderful', 'little', 'production', 'filming...</td>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>['thought', 'wonderful', 'way', 'spend', 'time...</td>\n",
       "      <td>['thought', 'wonder', 'way', 'spend', 'time', ...</td>\n",
       "      <td>['thought', 'wond', 'way', 'spend', 'tim', 'ho...</td>\n",
       "      <td>['thought', 'wonder', 'way', 'spend', 'time', ...</td>\n",
       "      <td>['thought', 'wonderful', 'way', 'spend', 'tim'...</td>\n",
       "      <td>['thought', 'wonderful', 'way', 'spend', 'time...</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>['basically', 'theres', 'family', 'little', 'b...</td>\n",
       "      <td>['basic', 'there', 'famili', 'littl', 'boy', '...</td>\n",
       "      <td>['bas', 'ther', 'famy', 'littl', 'boy', 'jak',...</td>\n",
       "      <td>['basic', 'there', 'famili', 'littl', 'boy', '...</td>\n",
       "      <td>['basically', 'there', 'family', 'littl', 'boy...</td>\n",
       "      <td>['basically', 'there', 'family', 'little', 'bo...</td>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>['petter', 'matteis', 'love', 'time', 'money',...</td>\n",
       "      <td>['petter', 'mattei', 'love', 'time', 'money', ...</td>\n",
       "      <td>['pet', 'mat', 'lov', 'tim', 'money', 'vis', '...</td>\n",
       "      <td>['petter', 'mattei', 'love', 'time', 'money', ...</td>\n",
       "      <td>['petter', 'mattei', 'lov', 'tim', 'money', 'v...</td>\n",
       "      <td>['petter', 'matteis', 'love', 'time', 'money',...</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review sentiment  \\\n",
       "0           0  one of the other reviewers has mentioned that ...  positive   \n",
       "1           1  a wonderful little production filming techniqu...  positive   \n",
       "2           2  i thought this was a wonderful way to spend ti...  positive   \n",
       "3           3  basically theres a family where a little boy j...  negative   \n",
       "4           4  petter matteis love in the time of money is a ...  positive   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  one reviewers mentioned watching 1 oz episode ...   \n",
       "1  wonderful little production filming technique ...   \n",
       "2  thought wonderful way spend time hot summer we...   \n",
       "3  basically theres family little boy jake thinks...   \n",
       "4  petter matteis love time money visually stunni...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  ['one', 'reviewers', 'mentioned', 'watching', ...   \n",
       "1  ['wonderful', 'little', 'production', 'filming...   \n",
       "2  ['thought', 'wonderful', 'way', 'spend', 'time...   \n",
       "3  ['basically', 'theres', 'family', 'little', 'b...   \n",
       "4  ['petter', 'matteis', 'love', 'time', 'money',...   \n",
       "\n",
       "                                      porter_stemmed  \\\n",
       "0  ['one', 'review', 'mention', 'watch', '1', 'oz...   \n",
       "1  ['wonder', 'littl', 'product', 'film', 'techni...   \n",
       "2  ['thought', 'wonder', 'way', 'spend', 'time', ...   \n",
       "3  ['basic', 'there', 'famili', 'littl', 'boy', '...   \n",
       "4  ['petter', 'mattei', 'love', 'time', 'money', ...   \n",
       "\n",
       "                                   lancaster_stemmed  \\\n",
       "0  ['on', 'review', 'ment', 'watch', '1', 'oz', '...   \n",
       "1  ['wond', 'littl', 'produc', 'film', 'techn', '...   \n",
       "2  ['thought', 'wond', 'way', 'spend', 'tim', 'ho...   \n",
       "3  ['bas', 'ther', 'famy', 'littl', 'boy', 'jak',...   \n",
       "4  ['pet', 'mat', 'lov', 'tim', 'money', 'vis', '...   \n",
       "\n",
       "                                   snowball_stemming  \\\n",
       "0  ['one', 'review', 'mention', 'watch', '1', 'oz...   \n",
       "1  ['wonder', 'littl', 'product', 'film', 'techni...   \n",
       "2  ['thought', 'wonder', 'way', 'spend', 'time', ...   \n",
       "3  ['basic', 'there', 'famili', 'littl', 'boy', '...   \n",
       "4  ['petter', 'mattei', 'love', 'time', 'money', ...   \n",
       "\n",
       "                                      regexp_stemmed  \\\n",
       "0  ['one', 'reviewer', 'mentioned', 'watch', '1',...   \n",
       "1  ['wonderful', 'littl', 'production', 'film', '...   \n",
       "2  ['thought', 'wonderful', 'way', 'spend', 'tim'...   \n",
       "3  ['basically', 'there', 'family', 'littl', 'boy...   \n",
       "4  ['petter', 'mattei', 'lov', 'tim', 'money', 'v...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  ['one', 'reviewer', 'mentioned', 'watching', '...   \n",
       "1  ['wonderful', 'little', 'production', 'filming...   \n",
       "2  ['thought', 'wonderful', 'way', 'spend', 'time...   \n",
       "3  ['basically', 'there', 'family', 'little', 'bo...   \n",
       "4  ['petter', 'matteis', 'love', 'time', 'money',...   \n",
       "\n",
       "                                              procss  \n",
       "0  one reviewer mentioned watching 1 oz episode y...  \n",
       "1  wonderful little production filming technique ...  \n",
       "2  thought wonderful way spend time hot summer we...  \n",
       "3  basically there family little boy jake think t...  \n",
       "4  petter matteis love time money visually stunni...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11c3153c-ce6e-45b8-822e-79aaebcb1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"Unnamed: 0\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1db92f-a3e4-4017-8a75-ba919c8d9e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"reviews.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f118aa1-6925-4917-924e-f806a3852654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14f1d0ef-3e3f-464e-b007-eb7ae9c3f229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           0\n",
       "review               0\n",
       "sentiment            0\n",
       "stopwords_removed    0\n",
       "tokenized            0\n",
       "porter_stemmed       0\n",
       "lancaster_stemmed    0\n",
       "snowball_stemming    0\n",
       "regexp_stemmed       0\n",
       "lemmatized           0\n",
       "proc                 0\n",
       "procss               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47bd4947-b773-4574-b721-4980f5c55e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e18c505-ad8b-463e-827a-718e5c43b36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92cb196a-7c7e-4236-b574-f7d589d5049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['procss'],\n",
    "                                                    df.sentiment,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=2022,\n",
    "                                                    stratify=df.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20aeb616-88ba-4585-a588-58e2605daa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with MultinomialNB\n",
      "Results for MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.87      5000\n",
      "    positive       0.88      0.85      0.86      5000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "\n",
      "Training with LogisticRegression\n",
      "Results for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89      5000\n",
      "    positive       0.88      0.90      0.89      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Training with LinearSVM\n",
      "Results for LinearSVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89      5000\n",
      "    positive       0.88      0.90      0.89      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'LinearSVM': LinearSVC()\n",
    "}\n",
    "\n",
    "# Loop through classifiers and train each\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining with {name}\")\n",
    "    \n",
    "    # Create pipeline for each classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('TFIDFvectorizer', TfidfVectorizer(ngram_range=(1, 1))),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd5ea02b-b466-4576-b136-2b7557ededa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with MultinomialNB\n",
      "Results for MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.89      5000\n",
      "    positive       0.90      0.87      0.88      5000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Training with LogisticRegression\n",
      "Results for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.88      5000\n",
      "    positive       0.87      0.91      0.89      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Training with LinearSVM\n",
      "Results for LinearSVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90      5000\n",
      "    positive       0.89      0.92      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'LinearSVM': LinearSVC()\n",
    "}\n",
    "\n",
    "# Loop through classifiers and train each\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining with {name}\")\n",
    "    \n",
    "    # Create pipeline for each classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('TFIDFvectorizer', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7374b1c3-99e7-4514-9051-83f627258ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with MultinomialNB\n",
      "Results for MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.89      5000\n",
      "    positive       0.89      0.88      0.88      5000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.89      0.88      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Training with LogisticRegression\n",
      "Results for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88      5000\n",
      "    positive       0.87      0.89      0.88      5000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Training with LinearSVM\n",
      "Results for LinearSVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90      5000\n",
      "    positive       0.89      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'LinearSVM': LinearSVC()\n",
    "}\n",
    "\n",
    "# Loop through classifiers and train each\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining with {name}\")\n",
    "    \n",
    "    # Create pipeline for each classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('TFIDFvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a9f99ad-377f-4fdd-99a3-e2f0fa17974a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with MultinomialNB\n",
      "Results for MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86      5000\n",
      "    positive       0.87      0.83      0.85      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n",
      "\n",
      "Training with LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88      5000\n",
      "    positive       0.88      0.89      0.88      5000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Training with LinearSVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LinearSVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86      5000\n",
      "    positive       0.86      0.87      0.86      5000\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'LinearSVM': LinearSVC()\n",
    "}\n",
    "\n",
    "# Loop through classifiers and train each\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining with {name}\")\n",
    "    \n",
    "    # Create pipeline for each classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('CountVectorizer', CountVectorizer(ngram_range=(1, 1))),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5bc9836-a28c-4545-8f35-fbbfec178c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with MultinomialNB\n",
      "Results for MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88      5000\n",
      "    positive       0.89      0.87      0.88      5000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.88      0.88      0.88     10000\n",
      "weighted avg       0.88      0.88      0.88     10000\n",
      "\n",
      "\n",
      "Training with LogisticRegression\n",
      "Results for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90      5000\n",
      "    positive       0.89      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "Training with LinearSVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LinearSVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89      5000\n",
      "    positive       0.89      0.90      0.90      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'LinearSVM': LinearSVC()\n",
    "}\n",
    "\n",
    "# Loop through classifiers and train each\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining with {name}\")\n",
    "    \n",
    "    # Create pipeline for each classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('CountVectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7642de2-3ea1-4e16-92f7-d52430d06100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with MultinomialNB\n",
      "Results for MultinomialNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89      5000\n",
      "    positive       0.90      0.87      0.88      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Training with LogisticRegression\n",
      "Results for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89      5000\n",
      "    positive       0.88      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Training with LinearSVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for LinearSVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89      5000\n",
      "    positive       0.89      0.90      0.90      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'LinearSVM': LinearSVC()\n",
    "}\n",
    "\n",
    "# Loop through classifiers and train each\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nTraining with {name}\")\n",
    "    \n",
    "    # Create pipeline for each classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('CountVectorizer', CountVectorizer(ngram_range=(1, 3))),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = pipeline.predict(x_test)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"Results for {name}:\")\n",
    "    print(classification_report(y_test, y_pred,zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f0504-e3e6-4ffd-bd28-1f330ce6734d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('TFIDFvectorizer', TfidfVectorizer(ngram_range=(1, 3))),\n",
    "    ('classifier', LinearSVC())\n",
    "])\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    #'classifier__max_iter': [1000, 2000, 5000],\n",
    "    'classifier__tol': [1e-4, 1e-3],#1e-5, 1e-4, 1e-3, 1e-2\n",
    "    'classifier__loss': ['hinge', 'squared_hinge'],\n",
    "    'classifier__penalty': ['l2'],#l1 can not be used whhen dual is true\n",
    "    'classifier__dual': [True, False],\n",
    "    'classifier__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=3)\n",
    "\n",
    "# Train the model\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Get the best pipeline and make predictions\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "y_pred = best_pipeline.predict(x_test)\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Results for best parameters:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Access and print all results from the grid search\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Loop through each parameter combination and score\n",
    "for i in range(len(results['params'])):\n",
    "    print(f\"Combination {i+1}:\")\n",
    "    print(f\"Params: {results['params'][i]}\")\n",
    "    print(f\"Mean Test Score: {results['mean_test_score'][i]}\")\n",
    "    print(f\"Rank: {results['rank_test_score'][i]}\")\n",
    "    print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
