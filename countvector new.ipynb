{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c55cc69-5593-4925-b6a9-c787a28af41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d537fe1-592b-4156-b272-51c78fcb31ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124989, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "      <th>headline</th>\n",
       "      <th>date</th>\n",
       "      <th>link</th>\n",
       "      <th>authors</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>2018-05-26</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   short_description  \\\n",
       "0  She left her husband. He killed their children...   \n",
       "1                           Of course it has a song.   \n",
       "2  The actor and his longtime girlfriend Anna Ebe...   \n",
       "3  The actor gives Dems an ass-kicking for not fi...   \n",
       "4  The \"Dietland\" actress said using the bags is ...   \n",
       "\n",
       "                                            headline       date  \\\n",
       "0  There Were 2 Mass Shootings In Texas Last Week... 2018-05-26   \n",
       "1  Will Smith Joins Diplo And Nicky Jam For The 2... 2018-05-26   \n",
       "2    Hugh Grant Marries For The First Time At Age 57 2018-05-26   \n",
       "3  Jim Carrey Blasts 'Castrato' Adam Schiff And D... 2018-05-26   \n",
       "4  Julianna Margulies Uses Donald Trump Poop Bags... 2018-05-26   \n",
       "\n",
       "                                                link          authors  \\\n",
       "0  https://www.huffingtonpost.com/entry/texas-ama...  Melissa Jeltsen   \n",
       "1  https://www.huffingtonpost.com/entry/will-smit...    Andy McDonald   \n",
       "2  https://www.huffingtonpost.com/entry/hugh-gran...       Ron Dicker   \n",
       "3  https://www.huffingtonpost.com/entry/jim-carre...       Ron Dicker   \n",
       "4  https://www.huffingtonpost.com/entry/julianna-...       Ron Dicker   \n",
       "\n",
       "        category  \n",
       "0          CRIME  \n",
       "1  ENTERTAINMENT  \n",
       "2  ENTERTAINMENT  \n",
       "3  ENTERTAINMENT  \n",
       "4  ENTERTAINMENT  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Try reading a single line first to check the format\n",
    "with open(\"dataset.json\", 'r') as f:\n",
    "    first_line = f.readline()\n",
    "\n",
    "try:\n",
    "    json.loads(first_line)  # Check if the first line is valid JSON\n",
    "    # If valid, read the entire file as a list of JSON objects\n",
    "    df = pd.read_json(\"dataset.json\", lines=True)\n",
    "except ValueError:\n",
    "    print(\"The file is not in a valid line-delimited JSON format.\")\n",
    "    # You might need to investigate the file structure further and adjust parsing accordingly\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df83e796-70cd-46a1-b7ef-d15938e2de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=['date','link','authors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63469682-b7e8-47ea-bd92-63228348e41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   short_description  \\\n",
       "0  She left her husband. He killed their children...   \n",
       "1                           Of course it has a song.   \n",
       "2  The actor and his longtime girlfriend Anna Ebe...   \n",
       "3  The actor gives Dems an ass-kicking for not fi...   \n",
       "4  The \"Dietland\" actress said using the bags is ...   \n",
       "\n",
       "                                            headline       category  \n",
       "0  There Were 2 Mass Shootings In Texas Last Week...          CRIME  \n",
       "1  Will Smith Joins Diplo And Nicky Jam For The 2...  ENTERTAINMENT  \n",
       "2    Hugh Grant Marries For The First Time At Age 57  ENTERTAINMENT  \n",
       "3  Jim Carrey Blasts 'Castrato' Adam Schiff And D...  ENTERTAINMENT  \n",
       "4  Julianna Margulies Uses Donald Trump Poop Bags...  ENTERTAINMENT  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea8efbb-825d-45da-a9af-9f0c30e16b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"langdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "917f890e-daed-4640-9f77-d08c0b255c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['short_description']=df['short_description'].str.lower()\n",
    "df['headline']=df['headline'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "913fb18d-79a6-44ed-a7b1-9e2c2768909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3741b50b-3734-45c6-9b1e-087ef6225b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['short_description']=df['short_description'].apply(removes_non_printables)\n",
    "df['headline']=df['headline'].apply(removes_non_printables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f6402a3-d92d-41a2-b8ad-cafc8ada91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['short_description']=df['short_description'].apply(removes_specials)\n",
    "df['headline']=df['headline'].apply(removes_specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6915e4-bae3-470f-9061-c0cdd2d3f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_lib import *\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"langdata.csv\")\n",
    "df['headline']=df['headline'].apply(preprocesswithlema)\n",
    "df['short_description']=df['short_description'].apply(preprocesswithlema)\n",
    "df.to_csv(\"langdata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66eef339-b405-4d8a-9715-bd3b280b7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"langdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef11d1fd-c049-4015-b26a-ffd316378fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['short_description', 'headline', 'category'], dtype='object')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "97aa55f7-6639-4b39-a548-a04147807d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e73ea158-8af7-4aca-afd8-33c7cb74c996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leave husband kill child day america</td>\n",
       "      <td>2 mass shooting texas week 1 tv</td>\n",
       "      <td>CRIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>course song</td>\n",
       "      <td>smith join diplo nicky jam 2018 world cups off...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actor longtime girlfriend anna eberstein tie k...</td>\n",
       "      <td>hugh grant marrie time age 57</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>actor give dem asskicking fight hard donald trump</td>\n",
       "      <td>jim carrey blasts castrato adam schiff democra...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dietland actress say bag cathartic therapeutic...</td>\n",
       "      <td>julianna margulie use donald trump poop bag pi...</td>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   short_description  \\\n",
       "0               leave husband kill child day america   \n",
       "1                                        course song   \n",
       "2  actor longtime girlfriend anna eberstein tie k...   \n",
       "3  actor give dem asskicking fight hard donald trump   \n",
       "4  dietland actress say bag cathartic therapeutic...   \n",
       "\n",
       "                                            headline       category  \n",
       "0                    2 mass shooting texas week 1 tv          CRIME  \n",
       "1  smith join diplo nicky jam 2018 world cups off...  ENTERTAINMENT  \n",
       "2                      hugh grant marrie time age 57  ENTERTAINMENT  \n",
       "3  jim carrey blasts castrato adam schiff democra...  ENTERTAINMENT  \n",
       "4  julianna margulie use donald trump poop bag pi...  ENTERTAINMENT  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f4d812db-fc37-42b5-b081-0b59224350e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['short_description'] = ds['short_description'].where(ds['short_description'].str.split().str.len() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5eb3bfc7-da90-433e-9537-1bd831afef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['headline'] = ds['headline'].where(ds['headline'].str.split().str.len() > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "82c51d60-7ff8-4cd9-895f-0629ab0e7e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "short_description    3279\n",
       "headline              545\n",
       "category                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5313672f-48c6-4900-9499-41301b501812",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5a14cd85-7737-40ed-b5ce-6058cc828908",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_csv(\"langdata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cbd6bfca-9225-49f7-8925-f8a507da3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"langdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d84c3f1b-9b5d-4b47-965a-2f0e42c81628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "short_description    0\n",
       "headline             0\n",
       "category             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "908de8f4-c8d9-4631-96dd-0b77afd112b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0e6324f2-c217-4e2b-85b0-719021737e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6f40fd32-c04f-4884-8376-f56fd50dcf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "31a33c8c-7e69-4276-8f44-3be73917a338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6dc31101-594c-45a6-85ca-ff14424625b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"langdata.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4dac3157-42fd-4f0d-b753-0717489e3b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100760, 3)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ab599c4a-679e-410f-b622-edf27d67497e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "POLITICS          28748\n",
       "ENTERTAINMENT     10655\n",
       "HEALTHY LIVING     5056\n",
       "QUEER VOICES       4095\n",
       "THE WORLDPOST      3632\n",
       "BLACK VOICES       3339\n",
       "BUSINESS           3337\n",
       "PARENTS            3284\n",
       "SPORTS             3282\n",
       "COMEDY             2953\n",
       "WOMEN              2887\n",
       "MEDIA              2224\n",
       "WORLD NEWS         2162\n",
       "IMPACT             2151\n",
       "CRIME              2141\n",
       "WEIRD NEWS         2038\n",
       "GREEN              2021\n",
       "TASTE              1801\n",
       "RELIGION           1800\n",
       "TRAVEL             1617\n",
       "STYLE              1314\n",
       "ARTS & CULTURE     1289\n",
       "WORLDPOST          1227\n",
       "TECH               1147\n",
       "FIFTY              1026\n",
       "LATINO VOICES       998\n",
       "GOOD NEWS           958\n",
       "SCIENCE             949\n",
       "COLLEGE             904\n",
       "EDUCATION           881\n",
       "ARTS                844\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b003947e-7dd9-4342-b610-4cab8f8a18f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5c1b5a99-2285-4096-bf85-f28dd9446e95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "ARTS              844\n",
      "GOOD NEWS         844\n",
      "SCIENCE           844\n",
      "EDUCATION         844\n",
      "ENTERTAINMENT     844\n",
      "STYLE             844\n",
      "SPORTS            844\n",
      "COLLEGE           844\n",
      "BLACK VOICES      844\n",
      "COMEDY            844\n",
      "PARENTS           844\n",
      "CRIME             844\n",
      "HEALTHY LIVING    844\n",
      "TRAVEL            844\n",
      "WORLDPOST         844\n",
      "GREEN             844\n",
      "POLITICS          844\n",
      "TECH              844\n",
      "BUSINESS          844\n",
      "IMPACT            844\n",
      "QUEER VOICES      844\n",
      "FIFTY             844\n",
      "WORLD NEWS        844\n",
      "RELIGION          844\n",
      "ARTS & CULTURE    844\n",
      "LATINO VOICES     844\n",
      "THE WORLDPOST     844\n",
      "WOMEN             844\n",
      "WEIRD NEWS        844\n",
      "MEDIA             844\n",
      "TASTE             844\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "undersampled_dfs = []\n",
    "min_samples=844\n",
    "for category in df['category'].unique():\n",
    "    df_category = df[df['category'] == category]\n",
    "    \n",
    "    df_category_undersampled = resample(df_category, \n",
    "                                        replace=False, \n",
    "                                        n_samples=min_samples, \n",
    "                                        random_state=1)\n",
    "    \n",
    "    undersampled_dfs.append(df_category_undersampled)\n",
    "\n",
    "df_undersampled = pd.concat(undersampled_dfs)\n",
    "\n",
    "df_undersampled = df_undersampled.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "print(df_undersampled['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a3ced7eb-6b73-4332-9899-81eccb8d5458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "short_description    0\n",
       "headline             0\n",
       "category             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_undersampled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c173feea-a7ac-49f4-a0ec-2066e8dedb10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_undersampled.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "684731a2-cf17-46f0-aa63-3e1194fc956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_undersampled.to_csv(\"langdatabalanced.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "58bc44ce-b566-4a60-90b8-62bd1e0af56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=pd.read_csv(\"langdatabalanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "865e87f9-eb4f-4158-b6ac-1477c315a94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "edcf904b-f8cd-4aa1-80b9-2b4eb358388d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26164</td>\n",
       "      <td>26164</td>\n",
       "      <td>26164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>26030</td>\n",
       "      <td>26149</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>need help maintain personal spiritual practice...</td>\n",
       "      <td>20 funniest tweet woman week</td>\n",
       "      <td>ARTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        short_description  \\\n",
       "count                                               26164   \n",
       "unique                                              26030   \n",
       "top     need help maintain personal spiritual practice...   \n",
       "freq                                                   43   \n",
       "\n",
       "                            headline category  \n",
       "count                          26164    26164  \n",
       "unique                         26149       31  \n",
       "top     20 funniest tweet woman week     ARTS  \n",
       "freq                               4      844  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b5d45b54-2517-4efe-ba1b-9629b66aa5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26164 entries, 0 to 26163\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   short_description  26164 non-null  object\n",
      " 1   headline           26164 non-null  object\n",
      " 2   category           26164 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 613.3+ KB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "228b9dd9-e1a9-47ce-a1dc-99b74d3c2b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Assuming 'short_description' is the column you want to use for features\n",
    "x_train, x_test, y_train, y_test = train_test_split(ds['short_description'],\n",
    "                                                    ds.category,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=2022,\n",
    "                                                    stratify=ds.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6919e9fe-9166-463b-af7f-846f9691a1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.25      0.56      0.35       169\n",
      "ARTS & CULTURE       0.31      0.05      0.09       169\n",
      "  BLACK VOICES       0.37      0.17      0.23       169\n",
      "      BUSINESS       0.29      0.36      0.32       169\n",
      "       COLLEGE       0.35      0.40      0.38       168\n",
      "        COMEDY       0.36      0.05      0.09       169\n",
      "         CRIME       0.41      0.47      0.44       169\n",
      "     EDUCATION       0.40      0.62      0.48       168\n",
      " ENTERTAINMENT       0.16      0.04      0.06       169\n",
      "         FIFTY       0.12      0.76      0.21       169\n",
      "     GOOD NEWS       0.17      0.05      0.08       169\n",
      "         GREEN       0.35      0.38      0.37       169\n",
      "HEALTHY LIVING       0.21      0.23      0.22       168\n",
      "        IMPACT       0.22      0.23      0.23       169\n",
      " LATINO VOICES       0.52      0.20      0.28       168\n",
      "         MEDIA       0.41      0.31      0.36       169\n",
      "       PARENTS       0.21      0.16      0.18       169\n",
      "      POLITICS       0.31      0.30      0.31       169\n",
      "  QUEER VOICES       0.49      0.21      0.29       169\n",
      "      RELIGION       0.36      0.33      0.34       169\n",
      "       SCIENCE       0.54      0.31      0.39       168\n",
      "        SPORTS       0.57      0.27      0.37       169\n",
      "         STYLE       0.49      0.23      0.31       169\n",
      "         TASTE       0.49      0.43      0.46       169\n",
      "          TECH       0.58      0.28      0.38       169\n",
      " THE WORLDPOST       0.45      0.17      0.24       169\n",
      "        TRAVEL       0.43      0.44      0.44       169\n",
      "    WEIRD NEWS       0.21      0.03      0.05       169\n",
      "         WOMEN       0.24      0.19      0.21       169\n",
      "    WORLD NEWS       0.29      0.08      0.12       169\n",
      "     WORLDPOST       0.24      0.79      0.37       168\n",
      "\n",
      "      accuracy                           0.29      5233\n",
      "     macro avg       0.35      0.29      0.28      5233\n",
      "  weighted avg       0.35      0.29      0.28      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer(ngram_range=(1, 1))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "60c22dde-9ac0-4418-9156-6db0cd9393ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.24      0.63      0.35       169\n",
      "ARTS & CULTURE       0.39      0.04      0.07       169\n",
      "  BLACK VOICES       0.39      0.14      0.21       169\n",
      "      BUSINESS       0.30      0.30      0.30       169\n",
      "       COLLEGE       0.36      0.39      0.37       168\n",
      "        COMEDY       0.48      0.07      0.11       169\n",
      "         CRIME       0.43      0.44      0.44       169\n",
      "     EDUCATION       0.39      0.64      0.48       168\n",
      " ENTERTAINMENT       0.20      0.04      0.06       169\n",
      "         FIFTY       0.10      0.82      0.18       169\n",
      "     GOOD NEWS       0.11      0.02      0.04       169\n",
      "         GREEN       0.37      0.37      0.37       169\n",
      "HEALTHY LIVING       0.31      0.21      0.25       168\n",
      "        IMPACT       0.20      0.21      0.21       169\n",
      " LATINO VOICES       0.51      0.17      0.25       168\n",
      "         MEDIA       0.44      0.30      0.35       169\n",
      "       PARENTS       0.21      0.11      0.15       169\n",
      "      POLITICS       0.34      0.28      0.31       169\n",
      "  QUEER VOICES       0.53      0.20      0.29       169\n",
      "      RELIGION       0.40      0.30      0.34       169\n",
      "       SCIENCE       0.61      0.31      0.41       168\n",
      "        SPORTS       0.57      0.22      0.32       169\n",
      "         STYLE       0.48      0.18      0.26       169\n",
      "         TASTE       0.51      0.37      0.43       169\n",
      "          TECH       0.64      0.19      0.29       169\n",
      " THE WORLDPOST       0.53      0.15      0.23       169\n",
      "        TRAVEL       0.46      0.40      0.43       169\n",
      "    WEIRD NEWS       0.25      0.02      0.04       169\n",
      "         WOMEN       0.30      0.17      0.22       169\n",
      "    WORLD NEWS       0.35      0.08      0.13       169\n",
      "     WORLDPOST       0.19      0.83      0.31       168\n",
      "\n",
      "      accuracy                           0.28      5233\n",
      "     macro avg       0.37      0.28      0.26      5233\n",
      "  weighted avg       0.37      0.28      0.26      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "01aa7696-f4b0-4739-aad6-b08fd518276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.24      0.63      0.34       169\n",
      "ARTS & CULTURE       0.35      0.04      0.06       169\n",
      "  BLACK VOICES       0.40      0.14      0.20       169\n",
      "      BUSINESS       0.31      0.30      0.30       169\n",
      "       COLLEGE       0.36      0.38      0.37       168\n",
      "        COMEDY       0.46      0.07      0.11       169\n",
      "         CRIME       0.43      0.43      0.43       169\n",
      "     EDUCATION       0.39      0.64      0.48       168\n",
      " ENTERTAINMENT       0.20      0.04      0.06       169\n",
      "         FIFTY       0.10      0.81      0.18       169\n",
      "     GOOD NEWS       0.11      0.02      0.04       169\n",
      "         GREEN       0.37      0.37      0.37       169\n",
      "HEALTHY LIVING       0.31      0.21      0.25       168\n",
      "        IMPACT       0.21      0.21      0.21       169\n",
      " LATINO VOICES       0.50      0.15      0.24       168\n",
      "         MEDIA       0.44      0.30      0.35       169\n",
      "       PARENTS       0.22      0.11      0.15       169\n",
      "      POLITICS       0.33      0.26      0.29       169\n",
      "  QUEER VOICES       0.55      0.20      0.29       169\n",
      "      RELIGION       0.40      0.30      0.34       169\n",
      "       SCIENCE       0.62      0.32      0.42       168\n",
      "        SPORTS       0.57      0.22      0.32       169\n",
      "         STYLE       0.47      0.17      0.24       169\n",
      "         TASTE       0.52      0.36      0.43       169\n",
      "          TECH       0.62      0.18      0.28       169\n",
      " THE WORLDPOST       0.51      0.14      0.22       169\n",
      "        TRAVEL       0.48      0.40      0.43       169\n",
      "    WEIRD NEWS       0.35      0.04      0.06       169\n",
      "         WOMEN       0.30      0.17      0.22       169\n",
      "    WORLD NEWS       0.36      0.08      0.13       169\n",
      "     WORLDPOST       0.19      0.84      0.31       168\n",
      "\n",
      "      accuracy                           0.27      5233\n",
      "     macro avg       0.38      0.27      0.26      5233\n",
      "  weighted avg       0.38      0.27      0.26      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer(ngram_range=(1, 3))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5c0bbd7c-95c2-4c78-9a3b-b5e63a5748fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x00000257DC285850>>\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 790, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\PCD\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1533, in enumerate\n",
      "    def enumerate():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MultinomialNB with CountVectorizer: {'classifier__alpha': 1.0, 'vectorizer__max_df': 0.7, 'vectorizer__min_df': 2, 'vectorizer__ngram_range': (1, 1), 'vectorizer__stop_words': 'english'}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Evaluate on test data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m grid_search_nb\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43maccuracy_score\u001b[49m(y_test, y_pred))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define parameter grid for MultinomialNB with CountVectorizer\n",
    "param_grid_nb = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'vectorizer__stop_words': [None, 'english'],\n",
    "    'vectorizer__max_df': [0.7, 0.9],\n",
    "    'vectorizer__min_df': [1, 2],\n",
    "    'classifier__alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# Grid search for MultinomialNB using CountVectorizer\n",
    "grid_search_nb = GridSearchCV(pipeline, param_grid_nb, cv=5, scoring='accuracy')\n",
    "grid_search_nb.fit(x_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters for MultinomialNB with CountVectorizer:\", grid_search_nb.best_params_)\n",
    "\n",
    "# Evaluate on test data\n",
    "y_pred = grid_search_nb.predict(x_test)\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2d80de29-a04d-4e9f-81c5-8c5e8c660953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.37      0.53      0.43       169\n",
      "ARTS & CULTURE       0.30      0.09      0.14       169\n",
      "  BLACK VOICES       0.34      0.20      0.25       169\n",
      "      BUSINESS       0.30      0.34      0.32       169\n",
      "       COLLEGE       0.36      0.41      0.38       168\n",
      "        COMEDY       0.27      0.10      0.15       169\n",
      "         CRIME       0.36      0.54      0.43       169\n",
      "     EDUCATION       0.43      0.61      0.50       168\n",
      " ENTERTAINMENT       0.16      0.06      0.09       169\n",
      "         FIFTY       0.15      0.63      0.24       169\n",
      "     GOOD NEWS       0.22      0.14      0.17       169\n",
      "         GREEN       0.37      0.41      0.39       169\n",
      "HEALTHY LIVING       0.24      0.25      0.24       168\n",
      "        IMPACT       0.25      0.27      0.26       169\n",
      " LATINO VOICES       0.44      0.25      0.32       168\n",
      "         MEDIA       0.44      0.37      0.40       169\n",
      "       PARENTS       0.28      0.29      0.28       169\n",
      "      POLITICS       0.32      0.38      0.35       169\n",
      "  QUEER VOICES       0.48      0.30      0.37       169\n",
      "      RELIGION       0.38      0.37      0.37       169\n",
      "       SCIENCE       0.52      0.39      0.45       168\n",
      "        SPORTS       0.50      0.36      0.42       169\n",
      "         STYLE       0.43      0.30      0.35       169\n",
      "         TASTE       0.44      0.52      0.48       169\n",
      "          TECH       0.47      0.34      0.39       169\n",
      " THE WORLDPOST       0.35      0.19      0.25       169\n",
      "        TRAVEL       0.48      0.49      0.49       169\n",
      "    WEIRD NEWS       0.26      0.08      0.13       169\n",
      "         WOMEN       0.27      0.25      0.26       169\n",
      "    WORLD NEWS       0.30      0.14      0.19       169\n",
      "     WORLDPOST       0.33      0.69      0.44       168\n",
      "\n",
      "      accuracy                           0.33      5233\n",
      "     macro avg       0.35      0.33      0.32      5233\n",
      "  weighted avg       0.35      0.33      0.32      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Import TfidfVectorizer\n",
    "\n",
    "# Define the pipeline with TfidfVectorizer instead of CountVectorizer\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer(ngram_range=(1, 1))),  # Use TF-IDF with n-grams (1, 2, 3)\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Output the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b2b6f6d1-e4e1-4097-a04c-0200d74ed447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.34      0.53      0.41       169\n",
      "ARTS & CULTURE       0.32      0.08      0.13       169\n",
      "  BLACK VOICES       0.37      0.20      0.25       169\n",
      "      BUSINESS       0.34      0.36      0.35       169\n",
      "       COLLEGE       0.40      0.45      0.42       168\n",
      "        COMEDY       0.24      0.09      0.14       169\n",
      "         CRIME       0.36      0.55      0.44       169\n",
      "     EDUCATION       0.46      0.65      0.54       168\n",
      " ENTERTAINMENT       0.20      0.08      0.11       169\n",
      "         FIFTY       0.15      0.67      0.25       169\n",
      "     GOOD NEWS       0.22      0.13      0.16       169\n",
      "         GREEN       0.37      0.40      0.39       169\n",
      "HEALTHY LIVING       0.26      0.27      0.27       168\n",
      "        IMPACT       0.26      0.24      0.25       169\n",
      " LATINO VOICES       0.48      0.24      0.32       168\n",
      "         MEDIA       0.42      0.37      0.39       169\n",
      "       PARENTS       0.26      0.27      0.27       169\n",
      "      POLITICS       0.32      0.37      0.34       169\n",
      "  QUEER VOICES       0.50      0.30      0.38       169\n",
      "      RELIGION       0.39      0.37      0.38       169\n",
      "       SCIENCE       0.52      0.38      0.44       168\n",
      "        SPORTS       0.53      0.37      0.44       169\n",
      "         STYLE       0.44      0.34      0.38       169\n",
      "         TASTE       0.45      0.51      0.48       169\n",
      "          TECH       0.40      0.32      0.36       169\n",
      " THE WORLDPOST       0.40      0.21      0.27       169\n",
      "        TRAVEL       0.49      0.47      0.48       169\n",
      "    WEIRD NEWS       0.33      0.10      0.15       169\n",
      "         WOMEN       0.27      0.25      0.26       169\n",
      "    WORLD NEWS       0.33      0.15      0.21       169\n",
      "     WORLDPOST       0.31      0.73      0.43       168\n",
      "\n",
      "      accuracy                           0.34      5233\n",
      "     macro avg       0.36      0.34      0.33      5233\n",
      "  weighted avg       0.36      0.34      0.33      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Import TfidfVectorizer\n",
    "\n",
    "# Define the pipeline with TfidfVectorizer instead of CountVectorizer\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer(ngram_range=(1, 2))),  # Use TF-IDF with n-grams (1, 2, 3)\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Output the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e68f465b-94b7-4ddc-b86e-ae830f2b50eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.34      0.52      0.41       169\n",
      "ARTS & CULTURE       0.33      0.08      0.12       169\n",
      "  BLACK VOICES       0.38      0.20      0.26       169\n",
      "      BUSINESS       0.35      0.36      0.35       169\n",
      "       COLLEGE       0.41      0.44      0.43       168\n",
      "        COMEDY       0.22      0.10      0.14       169\n",
      "         CRIME       0.35      0.54      0.43       169\n",
      "     EDUCATION       0.46      0.64      0.53       168\n",
      " ENTERTAINMENT       0.21      0.09      0.12       169\n",
      "         FIFTY       0.16      0.67      0.26       169\n",
      "     GOOD NEWS       0.22      0.14      0.17       169\n",
      "         GREEN       0.37      0.38      0.38       169\n",
      "HEALTHY LIVING       0.28      0.27      0.28       168\n",
      "        IMPACT       0.28      0.24      0.26       169\n",
      " LATINO VOICES       0.49      0.25      0.33       168\n",
      "         MEDIA       0.42      0.37      0.39       169\n",
      "       PARENTS       0.26      0.27      0.27       169\n",
      "      POLITICS       0.31      0.37      0.34       169\n",
      "  QUEER VOICES       0.51      0.31      0.38       169\n",
      "      RELIGION       0.39      0.37      0.38       169\n",
      "       SCIENCE       0.51      0.38      0.43       168\n",
      "        SPORTS       0.52      0.38      0.44       169\n",
      "         STYLE       0.41      0.34      0.37       169\n",
      "         TASTE       0.43      0.51      0.47       169\n",
      "          TECH       0.40      0.33      0.36       169\n",
      " THE WORLDPOST       0.41      0.21      0.28       169\n",
      "        TRAVEL       0.49      0.49      0.49       169\n",
      "    WEIRD NEWS       0.32      0.11      0.17       169\n",
      "         WOMEN       0.28      0.27      0.27       169\n",
      "    WORLD NEWS       0.31      0.15      0.20       169\n",
      "     WORLDPOST       0.31      0.71      0.44       168\n",
      "\n",
      "      accuracy                           0.34      5233\n",
      "     macro avg       0.36      0.34      0.33      5233\n",
      "  weighted avg       0.36      0.34      0.33      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Import TfidfVectorizer\n",
    "\n",
    "# Define the pipeline with TfidfVectorizer instead of CountVectorizer\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer(ngram_range=(1, 3))),  # Use TF-IDF with n-grams (1, 2, 3)\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Output the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "edeec922-aa75-43e3-b60d-80c9a149c802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MultinomialNB: {'classifier__alpha': 1.0, 'vectorizer__max_df': 0.7, 'vectorizer__min_df': 1, 'vectorizer__ngram_range': (1, 3), 'vectorizer__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define parameter grid for MultinomialNB\n",
    "param_grid_nb = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2),(1,3)],\n",
    "    'vectorizer__stop_words': [None, 'english'],\n",
    "    'vectorizer__max_df': [0.7, 0.9],\n",
    "    'vectorizer__min_df': [1, 2],\n",
    "    'classifier__alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# Grid search for MultinomialNB\n",
    "grid_search_nb = GridSearchCV(pipeline, param_grid_nb, cv=5, scoring='accuracy')\n",
    "grid_search_nb.fit(x_train, y_train)\n",
    "print(\"Best parameters for MultinomialNB:\", grid_search_nb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a06a14c7-6823-447c-909f-7e93ee299734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for MultinomialNB with best parameters:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.33      0.56      0.42       169\n",
      "ARTS & CULTURE       0.26      0.11      0.15       169\n",
      "  BLACK VOICES       0.33      0.19      0.24       169\n",
      "      BUSINESS       0.32      0.37      0.34       169\n",
      "       COLLEGE       0.39      0.43      0.41       168\n",
      "        COMEDY       0.31      0.11      0.16       169\n",
      "         CRIME       0.34      0.52      0.41       169\n",
      "     EDUCATION       0.47      0.64      0.54       168\n",
      " ENTERTAINMENT       0.16      0.07      0.10       169\n",
      "         FIFTY       0.19      0.63      0.30       169\n",
      "     GOOD NEWS       0.23      0.14      0.17       169\n",
      "         GREEN       0.36      0.41      0.38       169\n",
      "HEALTHY LIVING       0.24      0.24      0.24       168\n",
      "        IMPACT       0.27      0.25      0.26       169\n",
      " LATINO VOICES       0.48      0.26      0.33       168\n",
      "         MEDIA       0.42      0.39      0.41       169\n",
      "       PARENTS       0.24      0.28      0.26       169\n",
      "      POLITICS       0.32      0.38      0.35       169\n",
      "  QUEER VOICES       0.56      0.30      0.39       169\n",
      "      RELIGION       0.38      0.37      0.38       169\n",
      "       SCIENCE       0.48      0.42      0.45       168\n",
      "        SPORTS       0.50      0.38      0.43       169\n",
      "         STYLE       0.43      0.33      0.37       169\n",
      "         TASTE       0.43      0.53      0.48       169\n",
      "          TECH       0.42      0.33      0.37       169\n",
      " THE WORLDPOST       0.35      0.21      0.27       169\n",
      "        TRAVEL       0.47      0.51      0.49       169\n",
      "    WEIRD NEWS       0.18      0.06      0.09       169\n",
      "         WOMEN       0.28      0.25      0.27       169\n",
      "    WORLD NEWS       0.28      0.12      0.17       169\n",
      "     WORLDPOST       0.30      0.72      0.42       168\n",
      "\n",
      "      accuracy                           0.34      5233\n",
      "     macro avg       0.35      0.34      0.32      5233\n",
      "  weighted avg       0.35      0.34      0.32      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean the dataset by filling NaN values with an empty string\n",
    "x_train_clean = x_train.fillna('')\n",
    "x_test_clean = x_test.fillna('')\n",
    "\n",
    "# Create a pipeline with the best parameters for MultinomialNB\n",
    "best_pipeline_nb = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_df=0.7, min_df=2)),\n",
    "    ('classifier', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "# Train the pipeline on the cleaned training data\n",
    "best_pipeline_nb.fit(x_train_clean, y_train)\n",
    "\n",
    "# Predict on the cleaned test set\n",
    "y_pred_nb = best_pipeline_nb.predict(x_test_clean)\n",
    "\n",
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report for MultinomialNB with best parameters:\")\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d1d728d6-d4b5-4eb9-b594-d24564438829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for MultinomialNB with best parameters:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.34      0.53      0.41       169\n",
      "ARTS & CULTURE       0.30      0.08      0.13       169\n",
      "  BLACK VOICES       0.38      0.20      0.26       169\n",
      "      BUSINESS       0.33      0.36      0.34       169\n",
      "       COLLEGE       0.39      0.44      0.41       168\n",
      "        COMEDY       0.25      0.11      0.15       169\n",
      "         CRIME       0.35      0.54      0.42       169\n",
      "     EDUCATION       0.45      0.64      0.53       168\n",
      " ENTERTAINMENT       0.20      0.09      0.12       169\n",
      "         FIFTY       0.18      0.65      0.28       169\n",
      "     GOOD NEWS       0.21      0.15      0.17       169\n",
      "         GREEN       0.37      0.40      0.39       169\n",
      "HEALTHY LIVING       0.28      0.28      0.28       168\n",
      "        IMPACT       0.27      0.25      0.26       169\n",
      " LATINO VOICES       0.47      0.25      0.33       168\n",
      "         MEDIA       0.43      0.40      0.41       169\n",
      "       PARENTS       0.27      0.29      0.28       169\n",
      "      POLITICS       0.31      0.37      0.34       169\n",
      "  QUEER VOICES       0.50      0.31      0.38       169\n",
      "      RELIGION       0.39      0.38      0.38       169\n",
      "       SCIENCE       0.51      0.41      0.45       168\n",
      "        SPORTS       0.51      0.38      0.44       169\n",
      "         STYLE       0.42      0.33      0.37       169\n",
      "         TASTE       0.44      0.52      0.48       169\n",
      "          TECH       0.43      0.33      0.37       169\n",
      " THE WORLDPOST       0.40      0.20      0.27       169\n",
      "        TRAVEL       0.49      0.48      0.49       169\n",
      "    WEIRD NEWS       0.27      0.10      0.15       169\n",
      "         WOMEN       0.28      0.28      0.28       169\n",
      "    WORLD NEWS       0.27      0.14      0.19       169\n",
      "     WORLDPOST       0.31      0.72      0.44       168\n",
      "\n",
      "      accuracy                           0.34      5233\n",
      "     macro avg       0.36      0.34      0.33      5233\n",
      "  weighted avg       0.36      0.34      0.33      5233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean the dataset by filling NaN values with an empty string\n",
    "x_train_clean = x_train.fillna('')\n",
    "x_test_clean = x_test.fillna('')\n",
    "\n",
    "# Create a pipeline with the best parameters for MultinomialNB\n",
    "best_pipeline_nb = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1, 3), stop_words='english', max_df=0.7, min_df=1)),\n",
    "    ('classifier', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "# Train the pipeline on the cleaned training data\n",
    "best_pipeline_nb.fit(x_train_clean, y_train)\n",
    "\n",
    "# Predict on the cleaned test set\n",
    "y_pred_nb = best_pipeline_nb.predict(x_test_clean)\n",
    "\n",
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report for MultinomialNB with best parameters:\")\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
