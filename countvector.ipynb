{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e95563-c7f3-4199-b03e-7e9bfb04894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nlp_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86aa4e9e-8875-4343-afad-ba6ba28571ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=pd.read_csv(\"jsonds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e900d0aa-2c31-4dc9-b054-887cf8409d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['headline', 'short_description', 'category'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518412e6-7616-436e-ab66-9bb5fc1937b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds['headline']=ds['headline'].apply(removes_non_printables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "716caad9-c84a-49f3-b31c-4284e5e3b827",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['headline']=ds['headline'].apply(removes_specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61844a10-6488-4196-b33d-50c55cbc5698",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['short_description']=ds['short_description'].apply(removes_specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d4a751-2864-4bb3-87ee-708b1d7cc507",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['short_description']=ds['short_description'].apply(removes_non_printables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "163bf6ba-952b-4c50-833c-7ab25eebde10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['headline']=ds['headline'].apply(remove_stopwords)\n",
    "ds['short_description']=ds['short_description'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3c45a49-ecd6-4ec7-b119-4209c8ebe986",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['headline']=ds['headline'].apply(clean_text)\n",
    "ds['short_description']=ds['short_description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc3dbb3-87c1-4a99-af05-2616d4f1e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['headline']=ds['headline'].apply(remove_html_tags)\n",
    "ds['short_description']=ds['short_description'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00bbf52f-4464-4884-8b1a-b560e37765dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['headline']=ds['headline'].apply(remove_url)\n",
    "ds['short_description']=ds['short_description'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be7d7af4-818d-4c21-81ac-0598190db31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>letter straight white male sorry</td>\n",
       "      <td>affect like affect</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>super wealthy times columnist tom friedman att...</td>\n",
       "      <td>new york times pundit tom friedman apparently ...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tinder let swipe right presidential candidate ...</td>\n",
       "      <td>freak long term relationship whether like</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harry reid san bernardino shooting madness mus...</td>\n",
       "      <td>thursday reid introduce gun control amendment</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blueprint trump white house office american in...</td>\n",
       "      <td>innovation group measure effectiveness busines...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0                   letter straight white male sorry   \n",
       "1  super wealthy times columnist tom friedman att...   \n",
       "2  tinder let swipe right presidential candidate ...   \n",
       "3  harry reid san bernardino shooting madness mus...   \n",
       "4  blueprint trump white house office american in...   \n",
       "\n",
       "                                   short_description  category  \n",
       "0                                 affect like affect  POLITICS  \n",
       "1  new york times pundit tom friedman apparently ...  POLITICS  \n",
       "2          freak long term relationship whether like  POLITICS  \n",
       "3      thursday reid introduce gun control amendment  POLITICS  \n",
       "4  innovation group measure effectiveness busines...  POLITICS  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00904378-0b9d-4830-83e6-346f55a41a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>letter straight white male sorry</td>\n",
       "      <td>affect like affect</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>super wealthy times columnist tom friedman att...</td>\n",
       "      <td>new york times pundit tom friedman apparently ...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tinder let swipe right presidential candidate ...</td>\n",
       "      <td>freak long term relationship whether like</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harry reid san bernardino shooting madness mus...</td>\n",
       "      <td>thursday reid introduce gun control amendment</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blueprint trump white house office american in...</td>\n",
       "      <td>innovation group measure effectiveness busines...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0                   letter straight white male sorry   \n",
       "1  super wealthy times columnist tom friedman att...   \n",
       "2  tinder let swipe right presidential candidate ...   \n",
       "3  harry reid san bernardino shooting madness mus...   \n",
       "4  blueprint trump white house office american in...   \n",
       "\n",
       "                                   short_description  category  \n",
       "0                                 affect like affect  POLITICS  \n",
       "1  new york times pundit tom friedman apparently ...  POLITICS  \n",
       "2          freak long term relationship whether like  POLITICS  \n",
       "3      thursday reid introduce gun control amendment  POLITICS  \n",
       "4  innovation group measure effectiveness busines...  POLITICS  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "816241f5-24ae-4e8e-a426-6271deabf9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['headline']=ds['headline'].apply(preprocesswithlema)\n",
    "ds['short_description']=ds['short_description'].apply(preprocesswithlema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a16776fb-e8f7-4f7d-bb77-b5d438ef1a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>letter straight white male sorry</td>\n",
       "      <td>affect like affect</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>super wealthy times columnist tom friedman att...</td>\n",
       "      <td>new york times pundit tom friedman apparently ...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tinder let swipe right presidential candidate ...</td>\n",
       "      <td>freak long term relationship like</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harry reid san bernardino shooting madness stop</td>\n",
       "      <td>thursday reid introduce gun control amendment</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blueprint trump white house office american in...</td>\n",
       "      <td>innovation group measure effectiveness busines...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0                   letter straight white male sorry   \n",
       "1  super wealthy times columnist tom friedman att...   \n",
       "2  tinder let swipe right presidential candidate ...   \n",
       "3    harry reid san bernardino shooting madness stop   \n",
       "4  blueprint trump white house office american in...   \n",
       "\n",
       "                                   short_description  category  \n",
       "0                                 affect like affect  POLITICS  \n",
       "1  new york times pundit tom friedman apparently ...  POLITICS  \n",
       "2                  freak long term relationship like  POLITICS  \n",
       "3      thursday reid introduce gun control amendment  POLITICS  \n",
       "4  innovation group measure effectiveness busines...  POLITICS  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.to_csv(\"jsondsprocd.csv\")\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc90150-a657-4b2d-9738-311370742adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['headline']=ds['headline'].apply(wordnet_lemmatizing)\n",
    "ds['short_description']=ds['short_description'].apply(wordnet_lemmatizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5a67a2f-361c-4735-ab6d-bf48d087e2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Apply the function to the 'headline' and 'short_description' columns\n",
    "ds['headline'] = ds['headline'].apply(joint)\n",
    "ds['short_description'] = ds['short_description'].apply(joint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b045b4df-a725-40c4-a3d9-c96b57cf2d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>letter straight white male sorry</td>\n",
       "      <td>affect like affect</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>super wealthy times columnist tom friedman att...</td>\n",
       "      <td>new york times pundit tom friedman apparently ...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tinder let swipe right presidential candidate ...</td>\n",
       "      <td>freak long term relationship like</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harry reid san bernardino shooting madness stop</td>\n",
       "      <td>thursday reid introduce gun control amendment</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blueprint trump white house office american in...</td>\n",
       "      <td>innovation group measure effectiveness busines...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0                   letter straight white male sorry   \n",
       "1  super wealthy times columnist tom friedman att...   \n",
       "2  tinder let swipe right presidential candidate ...   \n",
       "3    harry reid san bernardino shooting madness stop   \n",
       "4  blueprint trump white house office american in...   \n",
       "\n",
       "                                   short_description  category  \n",
       "0                                 affect like affect  POLITICS  \n",
       "1  new york times pundit tom friedman apparently ...  POLITICS  \n",
       "2                  freak long term relationship like  POLITICS  \n",
       "3      thursday reid introduce gun control amendment  POLITICS  \n",
       "4  innovation group measure effectiveness busines...  POLITICS  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.to_csv(\"jsondsprocd2.csv\")\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13c60a7-898c-4888-9cd8-ea8172f8113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=pd.read_csv(\"jsondsprocd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b20fceb-bf4d-4555-a963-41bb720eb355",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=ds.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f81a730-9a08-4ab4-90bf-72f6fcc45799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Assuming 'short_description' is the column you want to use for features\n",
    "x_train, x_test, y_train, y_test = train_test_split(ds['short_description'],\n",
    "                                                    ds.category,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=2022,\n",
    "                                                    stratify=ds.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0f5c3d0-bcb4-456d-97b5-2f1a52491daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.27      0.27      0.27       201\n",
      "ARTS & CULTURE       0.33      0.08      0.13       201\n",
      "  BLACK VOICES       0.34      0.21      0.26       201\n",
      "      BUSINESS       0.23      0.23      0.23       201\n",
      "       COLLEGE       0.07      0.48      0.12       200\n",
      "        COMEDY       0.22      0.03      0.06       201\n",
      "         CRIME       0.41      0.32      0.36       201\n",
      "     EDUCATION       0.31      0.62      0.41       200\n",
      " ENTERTAINMENT       0.27      0.07      0.11       201\n",
      "         FIFTY       0.11      0.51      0.19       201\n",
      "     GOOD NEWS       0.13      0.02      0.03       201\n",
      "         GREEN       0.38      0.33      0.35       201\n",
      "HEALTHY LIVING       0.30      0.23      0.26       200\n",
      "        IMPACT       0.17      0.28      0.21       201\n",
      " LATINO VOICES       0.41      0.17      0.23       200\n",
      "         MEDIA       0.35      0.20      0.25       201\n",
      "       PARENTS       0.25      0.21      0.23       201\n",
      "      POLITICS       0.30      0.29      0.29       201\n",
      "  QUEER VOICES       0.48      0.19      0.28       201\n",
      "      RELIGION       0.47      0.31      0.37       201\n",
      "       SCIENCE       0.42      0.15      0.23       200\n",
      "        SPORTS       0.49      0.19      0.28       201\n",
      "         STYLE       0.42      0.08      0.14       201\n",
      "         TASTE       0.50      0.40      0.45       201\n",
      "          TECH       0.51      0.23      0.32       201\n",
      " THE WORLDPOST       0.35      0.24      0.29       201\n",
      "        TRAVEL       0.39      0.34      0.36       201\n",
      "    WEIRD NEWS       0.24      0.04      0.08       201\n",
      "         WOMEN       0.23      0.12      0.16       201\n",
      "    WORLD NEWS       0.34      0.23      0.27       201\n",
      "     WORLDPOST       0.23      0.27      0.25       200\n",
      "\n",
      "      accuracy                           0.24      6225\n",
      "     macro avg       0.32      0.24      0.24      6225\n",
      "  weighted avg       0.32      0.24      0.24      6225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import *\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer(ngram_range=(1, 1))),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0edb67b7-3d4c-4093-94a4-689461d5f56c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      5\u001b[0m clf \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectorizer_bow\u001b[39m\u001b[38;5;124m'\u001b[39m, CountVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))),\n\u001b[0;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, SVC())\n\u001b[0;32m      8\u001b[0m ])\n\u001b[1;32m---> 10\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, y_pred))\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:369\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    355\u001b[0m kernel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_kernels\u001b[38;5;241m.\u001b[39mindex(kernel)\n\u001b[0;32m    357\u001b[0m libsvm_sparse\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    359\u001b[0m (\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    362\u001b[0m     dual_coef_data,\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 369\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibsvm_sparse_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_weight_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m_libsvm_sparse.pyx:218\u001b[0m, in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:27\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_cs_matrix\u001b[39;00m(_data_matrix, _minmax_mixin, IndexMixin):\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    base array/matrix class for compressed row- and column-oriented arrays/matrices\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     28\u001b[0m         _data_matrix\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1)\n\u001b[0;32m     29\u001b[0m         is_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, sparray)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import *\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_bow', CountVectorizer(ngram_range=(1, 1))),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec12bf00-ca35-4f2a-8c07-9d18a6c4a5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.45      0.21      0.29       201\n",
      "ARTS & CULTURE       0.31      0.18      0.23       201\n",
      "  BLACK VOICES       0.34      0.25      0.29       201\n",
      "      BUSINESS       0.26      0.19      0.22       201\n",
      "       COLLEGE       0.07      0.47      0.12       200\n",
      "        COMEDY       0.34      0.10      0.15       201\n",
      "         CRIME       0.40      0.35      0.37       201\n",
      "     EDUCATION       0.33      0.66      0.44       200\n",
      " ENTERTAINMENT       0.24      0.08      0.12       201\n",
      "         FIFTY       0.15      0.41      0.22       201\n",
      "     GOOD NEWS       0.15      0.04      0.06       201\n",
      "         GREEN       0.43      0.35      0.39       201\n",
      "HEALTHY LIVING       0.28      0.23      0.26       200\n",
      "        IMPACT       0.20      0.26      0.23       201\n",
      " LATINO VOICES       0.39      0.23      0.29       200\n",
      "         MEDIA       0.40      0.23      0.30       201\n",
      "       PARENTS       0.24      0.31      0.27       201\n",
      "      POLITICS       0.27      0.34      0.30       201\n",
      "  QUEER VOICES       0.52      0.24      0.33       201\n",
      "      RELIGION       0.48      0.30      0.37       201\n",
      "       SCIENCE       0.47      0.20      0.28       200\n",
      "        SPORTS       0.43      0.24      0.31       201\n",
      "         STYLE       0.34      0.11      0.17       201\n",
      "         TASTE       0.43      0.49      0.46       201\n",
      "          TECH       0.42      0.35      0.38       201\n",
      " THE WORLDPOST       0.29      0.32      0.31       201\n",
      "        TRAVEL       0.44      0.38      0.41       201\n",
      "    WEIRD NEWS       0.20      0.06      0.09       201\n",
      "         WOMEN       0.20      0.15      0.17       201\n",
      "    WORLD NEWS       0.27      0.28      0.28       201\n",
      "     WORLDPOST       0.35      0.08      0.13       200\n",
      "\n",
      "      accuracy                           0.26      6225\n",
      "     macro avg       0.33      0.26      0.27      6225\n",
      "  weighted avg       0.33      0.26      0.27      6225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # Import TfidfVectorizer\n",
    "\n",
    "# Define the pipeline with TfidfVectorizer instead of CountVectorizer\n",
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer(ngram_range=(1, 2))),  # Use TF-IDF with n-grams (1, 2, 3)\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Output the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "692b17df-1e8f-49b9-b049-a05645ff276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.64      0.09      0.16       201\n",
      "ARTS & CULTURE       0.16      0.43      0.23       201\n",
      "  BLACK VOICES       0.31      0.23      0.27       201\n",
      "      BUSINESS       0.29      0.16      0.21       201\n",
      "       COLLEGE       0.55      0.28      0.37       200\n",
      "        COMEDY       0.17      0.10      0.13       201\n",
      "         CRIME       0.49      0.29      0.37       201\n",
      "     EDUCATION       0.65      0.52      0.58       200\n",
      " ENTERTAINMENT       0.16      0.15      0.16       201\n",
      "         FIFTY       0.31      0.26      0.28       201\n",
      "     GOOD NEWS       0.28      0.11      0.16       201\n",
      "         GREEN       0.53      0.31      0.39       201\n",
      "HEALTHY LIVING       0.29      0.23      0.26       200\n",
      "        IMPACT       0.18      0.17      0.18       201\n",
      " LATINO VOICES       0.39      0.25      0.31       200\n",
      "         MEDIA       0.43      0.21      0.29       201\n",
      "       PARENTS       0.27      0.32      0.29       201\n",
      "      POLITICS       0.26      0.31      0.28       201\n",
      "  QUEER VOICES       0.51      0.21      0.30       201\n",
      "      RELIGION       0.63      0.27      0.38       201\n",
      "       SCIENCE       0.45      0.23      0.30       200\n",
      "        SPORTS       0.40      0.25      0.31       201\n",
      "         STYLE       0.31      0.12      0.17       201\n",
      "         TASTE       0.41      0.46      0.43       201\n",
      "          TECH       0.24      0.40      0.30       201\n",
      " THE WORLDPOST       0.27      0.37      0.31       201\n",
      "        TRAVEL       0.51      0.34      0.41       201\n",
      "    WEIRD NEWS       0.17      0.12      0.14       201\n",
      "         WOMEN       0.23      0.21      0.22       201\n",
      "    WORLD NEWS       0.20      0.31      0.24       201\n",
      "     WORLDPOST       0.09      0.54      0.15       200\n",
      "\n",
      "      accuracy                           0.27      6225\n",
      "     macro avg       0.35      0.27      0.28      6225\n",
      "  weighted avg       0.35      0.27      0.28      6225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vectorizer_tfidf', TfidfVectorizer(ngram_range=(1, 1))),  # Use TF-IDF with n-grams (1, 2, 3)\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Output the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "054559d5-8380-448f-88dc-397686ce33b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.28      0.25      0.27       201\n",
      "ARTS & CULTURE       0.32      0.08      0.13       201\n",
      "  BLACK VOICES       0.34      0.22      0.27       201\n",
      "      BUSINESS       0.23      0.22      0.23       201\n",
      "       COLLEGE       0.07      0.46      0.12       200\n",
      "        COMEDY       0.25      0.04      0.07       201\n",
      "         CRIME       0.42      0.32      0.36       201\n",
      "     EDUCATION       0.30      0.64      0.40       200\n",
      " ENTERTAINMENT       0.27      0.06      0.10       201\n",
      "         FIFTY       0.12      0.53      0.19       201\n",
      "     GOOD NEWS       0.19      0.03      0.05       201\n",
      "         GREEN       0.38      0.32      0.35       201\n",
      "HEALTHY LIVING       0.31      0.23      0.27       200\n",
      "        IMPACT       0.17      0.29      0.21       201\n",
      " LATINO VOICES       0.41      0.17      0.24       200\n",
      "         MEDIA       0.34      0.20      0.25       201\n",
      "       PARENTS       0.26      0.22      0.24       201\n",
      "      POLITICS       0.29      0.30      0.30       201\n",
      "  QUEER VOICES       0.47      0.19      0.27       201\n",
      "      RELIGION       0.46      0.30      0.37       201\n",
      "       SCIENCE       0.43      0.15      0.23       200\n",
      "        SPORTS       0.51      0.20      0.29       201\n",
      "         STYLE       0.38      0.08      0.13       201\n",
      "         TASTE       0.49      0.42      0.46       201\n",
      "          TECH       0.52      0.25      0.34       201\n",
      " THE WORLDPOST       0.35      0.26      0.30       201\n",
      "        TRAVEL       0.42      0.34      0.38       201\n",
      "    WEIRD NEWS       0.20      0.04      0.07       201\n",
      "         WOMEN       0.23      0.13      0.17       201\n",
      "    WORLD NEWS       0.34      0.24      0.28       201\n",
      "     WORLDPOST       0.25      0.27      0.26       200\n",
      "\n",
      "      accuracy                           0.24      6225\n",
      "     macro avg       0.32      0.24      0.24      6225\n",
      "  weighted avg       0.32      0.24      0.24      6225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the pipeline with both CountVectorizer and TfidfVectorizer using FeatureUnion\n",
    "clf = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('vectorizer_bow', CountVectorizer(ngram_range=(1, 1))),   # CountVectorizer for bag-of-words\n",
    "        ('vectorizer_tfidf', TfidfVectorizer(ngram_range=(1, 1)))  # TfidfVectorizer\n",
    "    ])),\n",
    "    ('classifier', MultinomialNB())  # Naive Bayes classifier\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Output the classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da812be-7b23-49bc-acf0-f58b05d8cd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for MultinomialNB: {'classifier__alpha': 1.0, 'vectorizer__max_df': 0.7, 'vectorizer__min_df': 2, 'vectorizer__ngram_range': (1, 2), 'vectorizer__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define parameter grid for MultinomialNB\n",
    "param_grid_nb = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__stop_words': [None, 'english'],\n",
    "    'vectorizer__max_df': [0.7, 0.9],\n",
    "    'vectorizer__min_df': [1, 2],\n",
    "    'classifier__alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# Grid search for MultinomialNB\n",
    "grid_search_nb = GridSearchCV(pipeline, param_grid_nb, cv=5, scoring='accuracy')\n",
    "grid_search_nb.fit(x_train, y_train)\n",
    "print(\"Best parameters for MultinomialNB:\", grid_search_nb.best_params_)\n",
    "\n",
    "# Define parameter grid for SVC\n",
    "pipeline_svc = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "param_grid_svc = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__stop_words': [None, 'english'],\n",
    "    'vectorizer__max_df': [0.7, 0.9],\n",
    "    'vectorizer__min_df': [1, 2],\n",
    "    'classifier__C': [0.1, 1.0, 10.0],\n",
    "    'classifier__kernel': ['linear', 'rbf'],\n",
    "    'classifier__gamma': [0.001, 0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Grid search for SVC\n",
    "grid_search_svc = GridSearchCV(pipeline_svc, param_grid_svc, cv=5, scoring='accuracy')\n",
    "grid_search_svc.fit(x_train, y_train)\n",
    "print(\"Best parameters for SVC:\", grid_search_svc.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "360d42cc-bae2-41d9-a25d-18d068f7b508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for MultinomialNB with best parameters:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.70      0.17      0.27       115\n",
      "ARTS & CULTURE       0.24      0.34      0.28       199\n",
      "  BLACK VOICES       0.31      0.31      0.31       180\n",
      "      BUSINESS       0.34      0.25      0.29       157\n",
      "       COLLEGE       0.41      0.25      0.32       161\n",
      "        COMEDY       0.25      0.09      0.13       163\n",
      "         CRIME       0.40      0.38      0.39       152\n",
      "     EDUCATION       0.30      0.69      0.42       178\n",
      " ENTERTAINMENT       0.26      0.12      0.16       162\n",
      "         FIFTY       0.25      0.45      0.32       150\n",
      "     GOOD NEWS       0.12      0.03      0.04       145\n",
      "         GREEN       0.35      0.34      0.35       159\n",
      "HEALTHY LIVING       0.34      0.27      0.30       157\n",
      "        IMPACT       0.18      0.24      0.20       169\n",
      " LATINO VOICES       0.37      0.26      0.30       180\n",
      "         MEDIA       0.42      0.26      0.32       160\n",
      "       PARENTS       0.22      0.47      0.30       181\n",
      "      POLITICS       0.26      0.36      0.30       178\n",
      "  QUEER VOICES       0.51      0.33      0.40       168\n",
      "      RELIGION       0.54      0.26      0.35       144\n",
      "       SCIENCE       0.52      0.12      0.19       142\n",
      "        SPORTS       0.48      0.36      0.41       169\n",
      "         STYLE       0.54      0.11      0.18       132\n",
      "         TASTE       0.40      0.57      0.47       183\n",
      "          TECH       0.26      0.37      0.30       198\n",
      " THE WORLDPOST       0.24      0.47      0.31       200\n",
      "        TRAVEL       0.47      0.42      0.44       156\n",
      "    WEIRD NEWS       0.30      0.10      0.16       162\n",
      "         WOMEN       0.23      0.28      0.25       176\n",
      "    WORLD NEWS       0.27      0.41      0.33       200\n",
      "     WORLDPOST       0.33      0.01      0.02       100\n",
      "\n",
      "      accuracy                           0.31      5076\n",
      "     macro avg       0.35      0.29      0.28      5076\n",
      "  weighted avg       0.34      0.31      0.29      5076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "x_train_clean = x_train.dropna()\n",
    "y_train_clean = y_train[x_train_clean.index]  # Drop corresponding y values\n",
    "\n",
    "x_test_clean = x_test.dropna()\n",
    "y_test_clean = y_test[x_test_clean.index]  # Drop corresponding y values\n",
    "\n",
    "# Create a pipeline with the best parameters for MultinomialNB\n",
    "best_pipeline_nb = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_df=0.7, min_df=2)),\n",
    "    ('classifier', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "# Train the pipeline on the training data\n",
    "best_pipeline_nb.fit(x_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_nb = best_pipeline_nb.predict(x_test)\n",
    "\n",
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report for MultinomialNB with best parameters:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f03cbbca-8614-4e3a-80c4-5a83cd511d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for MultinomialNB with best parameters:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          ARTS       0.38      0.21      0.27       201\n",
      "ARTS & CULTURE       0.33      0.20      0.25       201\n",
      "  BLACK VOICES       0.31      0.25      0.28       201\n",
      "      BUSINESS       0.26      0.22      0.24       201\n",
      "       COLLEGE       0.07      0.48      0.13       200\n",
      "        COMEDY       0.25      0.10      0.14       201\n",
      "         CRIME       0.38      0.33      0.36       201\n",
      "     EDUCATION       0.35      0.62      0.45       200\n",
      " ENTERTAINMENT       0.26      0.08      0.13       201\n",
      "         FIFTY       0.16      0.40      0.23       201\n",
      "     GOOD NEWS       0.18      0.05      0.08       201\n",
      "         GREEN       0.40      0.34      0.36       201\n",
      "HEALTHY LIVING       0.29      0.26      0.27       200\n",
      "        IMPACT       0.19      0.22      0.20       201\n",
      " LATINO VOICES       0.38      0.23      0.28       200\n",
      "         MEDIA       0.37      0.23      0.29       201\n",
      "       PARENTS       0.23      0.28      0.25       201\n",
      "      POLITICS       0.26      0.29      0.27       201\n",
      "  QUEER VOICES       0.48      0.22      0.31       201\n",
      "      RELIGION       0.47      0.31      0.38       201\n",
      "       SCIENCE       0.44      0.21      0.29       200\n",
      "        SPORTS       0.44      0.25      0.32       201\n",
      "         STYLE       0.34      0.12      0.18       201\n",
      "         TASTE       0.42      0.48      0.45       201\n",
      "          TECH       0.42      0.35      0.38       201\n",
      " THE WORLDPOST       0.32      0.35      0.33       201\n",
      "        TRAVEL       0.45      0.41      0.43       201\n",
      "    WEIRD NEWS       0.22      0.07      0.11       201\n",
      "         WOMEN       0.24      0.15      0.19       201\n",
      "    WORLD NEWS       0.28      0.28      0.28       201\n",
      "     WORLDPOST       0.31      0.11      0.16       200\n",
      "\n",
      "      accuracy                           0.26      6225\n",
      "     macro avg       0.32      0.26      0.27      6225\n",
      "  weighted avg       0.32      0.26      0.27      6225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clean the dataset by filling NaN values with an empty string\n",
    "x_train_clean = x_train.fillna('')\n",
    "x_test_clean = x_test.fillna('')\n",
    "\n",
    "# Create a pipeline with the best parameters for MultinomialNB\n",
    "best_pipeline_nb = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_df=0.7, min_df=2)),\n",
    "    ('classifier', MultinomialNB(alpha=1.0))\n",
    "])\n",
    "\n",
    "# Train the pipeline on the cleaned training data\n",
    "best_pipeline_nb.fit(x_train_clean, y_train)\n",
    "\n",
    "# Predict on the cleaned test set\n",
    "y_pred_nb = best_pipeline_nb.predict(x_test_clean)\n",
    "\n",
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report for MultinomialNB with best parameters:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "066c6d12-9d22-4852-a023-e3c71ca2ce3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Grid search for SVC\u001b[39;00m\n\u001b[0;32m     20\u001b[0m grid_search_svc \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline_svc, param_grid_svc, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mgrid_search_svc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters for SVC:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search_svc\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m--> 473\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:369\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    355\u001b[0m kernel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_kernels\u001b[38;5;241m.\u001b[39mindex(kernel)\n\u001b[0;32m    357\u001b[0m libsvm_sparse\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    359\u001b[0m (\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    362\u001b[0m     dual_coef_data,\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 369\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibsvm_sparse_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_weight_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m_libsvm_sparse.pyx:218\u001b[0m, in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mG:\\Sem 7\\NLP\\Practicals\\venv\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:27\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_cs_matrix\u001b[39;00m(_data_matrix, _minmax_mixin, IndexMixin):\n\u001b[0;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    base array/matrix class for compressed row- and column-oriented arrays/matrices\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     28\u001b[0m         _data_matrix\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1)\n\u001b[0;32m     29\u001b[0m         is_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, sparray)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define parameter grid for SVC\n",
    "pipeline_svc = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "param_grid_svc = {\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vectorizer__stop_words': [None, 'english'],\n",
    "    'vectorizer__max_df': [0.7, 0.9],\n",
    "    'vectorizer__min_df': [1, 2],\n",
    "    'classifier__C': [0.1, 1.0, 10.0],\n",
    "    'classifier__kernel': ['linear', 'rbf'],\n",
    "    'classifier__gamma': [0.001, 0.01, 0.1, 1.0]\n",
    "}\n",
    "\n",
    "# Grid search for SVC\n",
    "grid_search_svc = GridSearchCV(pipeline_svc, param_grid_svc, cv=5, scoring='accuracy')\n",
    "grid_search_svc.fit(x_train, y_train)\n",
    "print(\"Best parameters for SVC:\", grid_search_svc.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
