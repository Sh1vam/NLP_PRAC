{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c97c95-e6c3-4eeb-81e9-a21f359eaed7",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a30da1e-3e4f-4dab-ada6-c4bd6d8798de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41b5721e-d682-4f04-bbf6-7cefadee43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(\"Twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68272832-b4f0-49f5-aef6-d09f046f108f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce0d4e71-56f2-482c-856d-34790c463c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"id\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c260049c-eb01-4046-aa9f-3aa12c11bcae",
   "metadata": {},
   "source": [
    "## Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ad2c824-e96d-480b-b8ba-e55deb993408",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet\"]=df[\"tweet\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5138e651-baa7-4764-b21d-bf680cfb50cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  #studiolife #aislife #requires #passion #dedic...\n",
       "1   @user #white #supremacists want everyone to s...\n",
       "2  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  is the hp and the cursed child book up for res...\n",
       "4    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc153ba1-c720-426f-a8b3-ee7b688ac618",
   "metadata": {},
   "source": [
    "## Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e8b4231-ae17-4b00-9f53-7a1e45546ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  3rd #bihday to my amazing, hilarious #nephew eli ahmir! uncle dave loves you and missesâ\\x80¦ '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b45e3aa-d5d3-460e-ae72-6bdd401ee873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet\"]=df[\"tweet\"].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04b8331a-ab9d-45f2-80e3-cc15eafbe409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user white supremacists want everyone to see t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd bihday to my amazing hilarious nephew eli ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  studiolife aislife requires passion dedication...\n",
       "1  user white supremacists want everyone to see t...\n",
       "2  safe ways to heal your acne    altwaystoheal h...\n",
       "3  is the hp and the cursed child book up for res...\n",
       "4  3rd bihday to my amazing hilarious nephew eli ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de6b7a45-e2a8-4c42-96bc-3e9e8bbaf2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3rd bihday to my amazing hilarious nephew eli ahmir uncle dave loves you and missesâ\\x80¦'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet\"][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580bd57-ccc1-4abb-89b9-cb4e34c40661",
   "metadata": {},
   "source": [
    "## Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74be34f0-88f8-444e-8485-b1358ae70cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tweet\"]=df[\"tweet\"].apply(removes_specials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb6c64ab-5ac4-468e-8988-2d0e9edb0468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3rd bihday to my amazing hilarious nephew eli ahmir uncle dave loves you and misses'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet\"][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c9298-c1c1-4265-9a81-4130ccd3a14e",
   "metadata": {},
   "source": [
    "## Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f1f7d71-f9f4-4500-8ed1-5e72aaf6c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rm_stop_words\"]=df[\"tweet\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59845393-d238-4c29-9c76-29dd093e634e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>rm_stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user white supremacists want everyone to see t...</td>\n",
       "      <td>user white supremacists want everyone see new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>safe ways heal acne altwaystoheal healthy healing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>hp cursed child book reservations already yes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd bihday to my amazing hilarious nephew eli ...</td>\n",
       "      <td>3rd bihday amazing hilarious nephew eli ahmir ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1  user white supremacists want everyone to see t...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4  3rd bihday to my amazing hilarious nephew eli ...   \n",
       "\n",
       "                                       rm_stop_words  \n",
       "0  studiolife aislife requires passion dedication...  \n",
       "1  user white supremacists want everyone see new ...  \n",
       "2  safe ways heal acne altwaystoheal healthy healing  \n",
       "3  hp cursed child book reservations already yes ...  \n",
       "4  3rd bihday amazing hilarious nephew eli ahmir ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc511ce4-c03a-496b-8c20-b168b9619613",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee08383d-c384-4d5c-b34e-8a8882c25517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spelling(text):\n",
    "    words = text.split()\n",
    "    corrected_words = [spell.correction(word) if spell.correction(word) else word for word in words]\n",
    "    return ' '.join(corrected_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9842a81-9866-4493-a2bd-2255d515dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['corrected_text'] = df['rm_stop_words'].apply(correct_spelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d219e145-e338-4364-8e85-80aaa660c01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3rd bihday amazing hilarious nephew eli ahmir uncle dave loves misses'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rm_stop_words'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ad19dab-b9e4-4245-9f67-d32c7798a849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and birthday amazing hilarious nephew elf amir uncle have loves misses'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_spelling(df['rm_stop_words'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2215e974-9f26-4a6d-baa8-83ba86de52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e9013-df75-49fd-9d6e-eb90fa7ac0ca",
   "metadata": {},
   "source": [
    "## Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "717538d4-3d1e-4dcf-9406-9f2d7d45ae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokenized_text\"] =df[\"rm_stop_words\"].apply(tokenized_text) #df[\"corrected_text\"].apply(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3a70453-ccb8-424a-ae88-4c4e6e78146d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>rm_stop_words</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user white supremacists want everyone to see t...</td>\n",
       "      <td>user white supremacists want everyone see new ...</td>\n",
       "      <td>[user, white, supremacists, want, everyone, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>safe ways heal acne altwaystoheal healthy healing</td>\n",
       "      <td>[safe, ways, heal, acne, altwaystoheal, health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>hp cursed child book reservations already yes ...</td>\n",
       "      <td>[hp, cursed, child, book, reservations, alread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd bihday to my amazing hilarious nephew eli ...</td>\n",
       "      <td>3rd bihday amazing hilarious nephew eli ahmir ...</td>\n",
       "      <td>[3rd, bihday, amazing, hilarious, nephew, eli,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1  user white supremacists want everyone to see t...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4  3rd bihday to my amazing hilarious nephew eli ...   \n",
       "\n",
       "                                       rm_stop_words  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1  user white supremacists want everyone see new ...   \n",
       "2  safe ways heal acne altwaystoheal healthy healing   \n",
       "3  hp cursed child book reservations already yes ...   \n",
       "4  3rd bihday amazing hilarious nephew eli ahmir ...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [studiolife, aislife, requires, passion, dedic...  \n",
       "1  [user, white, supremacists, want, everyone, se...  \n",
       "2  [safe, ways, heal, acne, altwaystoheal, health...  \n",
       "3  [hp, cursed, child, book, reservations, alread...  \n",
       "4  [3rd, bihday, amazing, hilarious, nephew, eli,...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3feb7c-65b5-4b11-9e71-02e9da08aa1d",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3604ad0f-42cc-4c8e-98c7-d3f6d8ba28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"porter_stemmed_text\"] = df[\"tokenized_text\"].apply(porter_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfe5688a-f506-4708-93cb-a3c81d960660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lancaster_stemmed_text\"] = df[\"tokenized_text\"].apply(lancaster_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7331972-04a8-435a-a6e1-2786e8f3c0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"snowball_stemmed_text\"] = df[\"tokenized_text\"].apply(snowball_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d973216c-4110-40a4-83d9-7d5c285d75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"regexp_stemmed_text\"] = df[\"tokenized_text\"].apply(regexp_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff4a424a-4c7d-4eae-83cc-0a27c69c7b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>porter_stemmed_text</th>\n",
       "      <th>lancaster_stemmed_text</th>\n",
       "      <th>snowball_stemmed_text</th>\n",
       "      <th>regexp_stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
       "      <td>[studiol, aisl, requir, pass, ded, willpow, fi...</td>\n",
       "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
       "      <td>[studiolif, aislif, require, passion, dedicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user white supremacists want everyone to see t...</td>\n",
       "      <td>[user, white, supremacist, want, everyon, see,...</td>\n",
       "      <td>[us, whit, supremac, want, everyon, see, new, ...</td>\n",
       "      <td>[user, white, supremacist, want, everyon, see,...</td>\n",
       "      <td>[user, whit, supremacist, want, everyon, see, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>[safe, way, heal, acn, altwaystoh, healthi, heal]</td>\n",
       "      <td>[saf, way, heal, acn, altwaystoh, healthy, heal]</td>\n",
       "      <td>[safe, way, heal, acn, altwaystoh, healthi, heal]</td>\n",
       "      <td>[saf, way, heal, acn, altwaystoheal, healthy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[hp, curs, child, book, reserv, alreadi, ye, h...</td>\n",
       "      <td>[hp, curs, child, book, reserv, already, ye, h...</td>\n",
       "      <td>[hp, curs, child, book, reserv, alreadi, yes, ...</td>\n",
       "      <td>[hp, cursed, child, book, reservation, already...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd bihday to my amazing hilarious nephew eli ...</td>\n",
       "      <td>[3rd, bihday, amaz, hilari, nephew, eli, ahmir...</td>\n",
       "      <td>[3rd, bihday, amaz, hil, nephew, el, ahmir, un...</td>\n",
       "      <td>[3rd, bihday, amaz, hilari, nephew, eli, ahmir...</td>\n",
       "      <td>[3rd, bihday, amaz, hilariou, nephew, eli, ahm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1  user white supremacists want everyone to see t...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4  3rd bihday to my amazing hilarious nephew eli ...   \n",
       "\n",
       "                                 porter_stemmed_text  \\\n",
       "0  [studiolif, aislif, requir, passion, dedic, wi...   \n",
       "1  [user, white, supremacist, want, everyon, see,...   \n",
       "2  [safe, way, heal, acn, altwaystoh, healthi, heal]   \n",
       "3  [hp, curs, child, book, reserv, alreadi, ye, h...   \n",
       "4  [3rd, bihday, amaz, hilari, nephew, eli, ahmir...   \n",
       "\n",
       "                              lancaster_stemmed_text  \\\n",
       "0  [studiol, aisl, requir, pass, ded, willpow, fi...   \n",
       "1  [us, whit, supremac, want, everyon, see, new, ...   \n",
       "2   [saf, way, heal, acn, altwaystoh, healthy, heal]   \n",
       "3  [hp, curs, child, book, reserv, already, ye, h...   \n",
       "4  [3rd, bihday, amaz, hil, nephew, el, ahmir, un...   \n",
       "\n",
       "                               snowball_stemmed_text  \\\n",
       "0  [studiolif, aislif, requir, passion, dedic, wi...   \n",
       "1  [user, white, supremacist, want, everyon, see,...   \n",
       "2  [safe, way, heal, acn, altwaystoh, healthi, heal]   \n",
       "3  [hp, curs, child, book, reserv, alreadi, yes, ...   \n",
       "4  [3rd, bihday, amaz, hilari, nephew, eli, ahmir...   \n",
       "\n",
       "                                 regexp_stemmed_text  \n",
       "0  [studiolif, aislif, require, passion, dedicati...  \n",
       "1  [user, whit, supremacist, want, everyon, see, ...  \n",
       "2  [saf, way, heal, acn, altwaystoheal, healthy, ...  \n",
       "3  [hp, cursed, child, book, reservation, already...  \n",
       "4  [3rd, bihday, amaz, hilariou, nephew, eli, ahm...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['rm_stop_words',\"tokenized_text\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a949e-feda-4dc4-9ca5-f215b902d750",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17f3f110-bfc8-4282-9927-c67d2ba0cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"wordnet_lemmatized_text\"] = df[\"tokenized_text\"].apply(wordnet_lemmatizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c492c1b-dad7-4529-8a4b-960ae727aac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>porter_stemmed_text</th>\n",
       "      <th>lancaster_stemmed_text</th>\n",
       "      <th>snowball_stemmed_text</th>\n",
       "      <th>regexp_stemmed_text</th>\n",
       "      <th>wordnet_lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
       "      <td>[studiol, aisl, requir, pass, ded, willpow, fi...</td>\n",
       "      <td>[studiolif, aislif, requir, passion, dedic, wi...</td>\n",
       "      <td>[studiolif, aislif, require, passion, dedicati...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user white supremacists want everyone to see t...</td>\n",
       "      <td>[user, white, supremacist, want, everyon, see,...</td>\n",
       "      <td>[us, whit, supremac, want, everyon, see, new, ...</td>\n",
       "      <td>[user, white, supremacist, want, everyon, see,...</td>\n",
       "      <td>[user, whit, supremacist, want, everyon, see, ...</td>\n",
       "      <td>[user, white, supremacist, want, everyone, see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>[safe, way, heal, acn, altwaystoh, healthi, heal]</td>\n",
       "      <td>[saf, way, heal, acn, altwaystoh, healthy, heal]</td>\n",
       "      <td>[safe, way, heal, acn, altwaystoh, healthi, heal]</td>\n",
       "      <td>[saf, way, heal, acn, altwaystoheal, healthy, ...</td>\n",
       "      <td>[safe, way, heal, acne, altwaystoheal, healthy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>[hp, curs, child, book, reserv, alreadi, ye, h...</td>\n",
       "      <td>[hp, curs, child, book, reserv, already, ye, h...</td>\n",
       "      <td>[hp, curs, child, book, reserv, alreadi, yes, ...</td>\n",
       "      <td>[hp, cursed, child, book, reservation, already...</td>\n",
       "      <td>[hp, cursed, child, book, reservation, already...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd bihday to my amazing hilarious nephew eli ...</td>\n",
       "      <td>[3rd, bihday, amaz, hilari, nephew, eli, ahmir...</td>\n",
       "      <td>[3rd, bihday, amaz, hil, nephew, el, ahmir, un...</td>\n",
       "      <td>[3rd, bihday, amaz, hilari, nephew, eli, ahmir...</td>\n",
       "      <td>[3rd, bihday, amaz, hilariou, nephew, eli, ahm...</td>\n",
       "      <td>[3rd, bihday, amazing, hilarious, nephew, eli,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1  user white supremacists want everyone to see t...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4  3rd bihday to my amazing hilarious nephew eli ...   \n",
       "\n",
       "                                 porter_stemmed_text  \\\n",
       "0  [studiolif, aislif, requir, passion, dedic, wi...   \n",
       "1  [user, white, supremacist, want, everyon, see,...   \n",
       "2  [safe, way, heal, acn, altwaystoh, healthi, heal]   \n",
       "3  [hp, curs, child, book, reserv, alreadi, ye, h...   \n",
       "4  [3rd, bihday, amaz, hilari, nephew, eli, ahmir...   \n",
       "\n",
       "                              lancaster_stemmed_text  \\\n",
       "0  [studiol, aisl, requir, pass, ded, willpow, fi...   \n",
       "1  [us, whit, supremac, want, everyon, see, new, ...   \n",
       "2   [saf, way, heal, acn, altwaystoh, healthy, heal]   \n",
       "3  [hp, curs, child, book, reserv, already, ye, h...   \n",
       "4  [3rd, bihday, amaz, hil, nephew, el, ahmir, un...   \n",
       "\n",
       "                               snowball_stemmed_text  \\\n",
       "0  [studiolif, aislif, requir, passion, dedic, wi...   \n",
       "1  [user, white, supremacist, want, everyon, see,...   \n",
       "2  [safe, way, heal, acn, altwaystoh, healthi, heal]   \n",
       "3  [hp, curs, child, book, reserv, alreadi, yes, ...   \n",
       "4  [3rd, bihday, amaz, hilari, nephew, eli, ahmir...   \n",
       "\n",
       "                                 regexp_stemmed_text  \\\n",
       "0  [studiolif, aislif, require, passion, dedicati...   \n",
       "1  [user, whit, supremacist, want, everyon, see, ...   \n",
       "2  [saf, way, heal, acn, altwaystoheal, healthy, ...   \n",
       "3  [hp, cursed, child, book, reservation, already...   \n",
       "4  [3rd, bihday, amaz, hilariou, nephew, eli, ahm...   \n",
       "\n",
       "                             wordnet_lemmatized_text  \n",
       "0  [studiolife, aislife, requires, passion, dedic...  \n",
       "1  [user, white, supremacist, want, everyone, see...  \n",
       "2  [safe, way, heal, acne, altwaystoheal, healthy...  \n",
       "3  [hp, cursed, child, book, reservation, already...  \n",
       "4  [3rd, bihday, amazing, hilarious, nephew, eli,...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['rm_stop_words',\"tokenized_text\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43184eec-637b-40f2-97e0-5e6424b5405a",
   "metadata": {},
   "source": [
    "## Part-of-Speech (POS) Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78e93d06-424c-4ff8-ba05-4d238b3225b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67c9f20f-cd36-41eb-a0c6-47b1cc1efa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"proc\"] = df[\"wordnet_lemmatized_text\"].apply(list_joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d25c047e-6694-430d-9b59-f83ed5dd79a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3rd bihday amazing hilarious nephew eli ahmir uncle dave love miss'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"proc\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a28f7b5-c6dd-4794-bb9e-163d8f26c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pos\"] = df[\"proc\"].apply(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bcae502a-6417-4c42-9931-60f007702f4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>proc</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>[(studiolife, NOUN), (aislife, PROPN), (requir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user white supremacists want everyone to see t...</td>\n",
       "      <td>user white supremacist want everyone see new b...</td>\n",
       "      <td>[(user, PROPN), (white, PROPN), (supremacist, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
       "      <td>safe way heal acne altwaystoheal healthy healing</td>\n",
       "      <td>[(safe, ADJ), (way, NOUN), (heal, VERB), (acne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>hp cursed child book reservation already yes h...</td>\n",
       "      <td>[(hp, PRON), (cursed, VERB), (child, NOUN), (b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd bihday to my amazing hilarious nephew eli ...</td>\n",
       "      <td>3rd bihday amazing hilarious nephew eli ahmir ...</td>\n",
       "      <td>[(3rd, ADJ), (bihday, NOUN), (amazing, ADJ), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1  user white supremacists want everyone to see t...   \n",
       "2  safe ways to heal your acne    altwaystoheal h...   \n",
       "3  is the hp and the cursed child book up for res...   \n",
       "4  3rd bihday to my amazing hilarious nephew eli ...   \n",
       "\n",
       "                                                proc  \\\n",
       "0  studiolife aislife requires passion dedication...   \n",
       "1  user white supremacist want everyone see new b...   \n",
       "2   safe way heal acne altwaystoheal healthy healing   \n",
       "3  hp cursed child book reservation already yes h...   \n",
       "4  3rd bihday amazing hilarious nephew eli ahmir ...   \n",
       "\n",
       "                                                 pos  \n",
       "0  [(studiolife, NOUN), (aislife, PROPN), (requir...  \n",
       "1  [(user, PROPN), (white, PROPN), (supremacist, ...  \n",
       "2  [(safe, ADJ), (way, NOUN), (heal, VERB), (acne...  \n",
       "3  [(hp, PRON), (cursed, VERB), (child, NOUN), (b...  \n",
       "4  [(3rd, ADJ), (bihday, NOUN), (amazing, ADJ), (...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tweet','proc','pos']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3b38bc4-a7be-4593-bbe7-c065c2d77175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain(\"PROPN\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
